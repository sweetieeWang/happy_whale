# æœºå™¨å­¦ä¹ æ¦‚è®º

## æ•°å­¦çŸ¥è¯†å¤ä¹ 

### çŸ©é˜µæ±‚å¯¼

$$
\begin{array}{l}\frac{\partial \mathbf{x}^{T} \mathbf{a}}{\partial \mathbf{x}}=\frac{\partial \mathbf{a}^{T} \mathbf{x}}{\partial \mathbf{x}}=\mathbf{a} \\ \frac{\partial \mathbf{a}^{T} \mathbf{X} \mathbf{b}}{\partial \mathbf{X}}=\mathbf{a b}^{T} \\ \frac{\partial \mathbf{a}^{T} \mathbf{X}^{T} \mathbf{b}}{\partial \mathbf{X}}=\mathbf{b a}^{T} \\ \frac{\partial \mathbf{a}^{T} \mathbf{X} \mathbf{a}}{\partial \mathbf{X}}=\frac{\partial \mathbf{a}^{T} \mathbf{X}^{T} \mathbf{a}}{\partial \mathbf{X}}=\mathbf{a a}^{T} \\ \frac{\partial \mathbf{x}^{T} \mathbf{B} \mathbf{x}}{\partial \mathbf{x}}=\left(\mathbf{B}+\mathbf{B}^{T}\right) \mathbf{x}\end{array}
$$

![æœºå™¨å­¦ä¹ .](/Users/wangjing/Downloads/æœºå™¨å­¦ä¹ ..png)

# å¤šå…ƒçº¿æ€§å›å½’

### å‡½æ•°æ¨¡å‹

**å‡½æ•°å½¢å¼**
$$
f(x)=\theta_{0}+\theta_{1} x_{1}+\cdots+\theta_{p} x_{p}
$$
**å‘é‡å½¢å¼**ï¼š

é€šå¸¸ä¸€ä¸ªå‘é‡æŒ‡çš„éƒ½æ˜¯åˆ—å‘é‡ï¼Œå‘é‡çš„è½¬ç½®æ˜¯è¡Œå‘é‡
$$
f(x)=\sum_{i=0}^{p} \theta_{i} x_{i}=\boldsymbol{\theta}^{T} x=x^{T} \boldsymbol{\theta} = \left[\left(x_{0}=1\right), x_{1}, x_{2}, \ldots, x_{p}\right]\left[\begin{array}{c}\theta_{0} \\ \theta_{1} \\ \vdots \\ \theta_{p}\end{array}\right]
$$
æŸå¤±å‡½æ•°ï¼šæœ€å°å‡æ–¹è¯¯å·®MSEï¼š
$$
J(\theta)=\frac{1}{2} \sum_{i=1}^{n}\left(x_{i}^{T} \theta-y_{i}\right)^{2}
$$
çº¿æ€§å›å½’æ¨¡å‹ï¼šæ±‚è§£æŸå¤±å‡½æ•°çš„æœ€å°å€¼
$$
\theta^* = arg minJ(\theta)
$$

### åŠ å…¥æ•°æ®åçš„æ¨¡å‹

nç»„æ•°æ®

é¢„æµ‹å€¼ï¼š
$$
\hat Y = X\theta=\left[\begin{array}{l} X_1^T\theta \\X_2^T\theta \\ \ldots \\X_n^T\theta \\  \end{array}\right]=\left[\begin{array}{l} X_{11}\space X_{12}\ldots X_{1p}\\X_{21}\space X_{22}\ldots X_{2p} \\ \ldots \\X_{n1}\space X_{n2}\ldots X_{np} \\\end{array}\right]\left[\begin{array}{c}\theta_{0} \\ \theta_{1} \\ \vdots \\ \theta_{p}\end{array}\right]
$$
å®é™…å€¼label (nç»„æ•°æ®nä¸ªlabel)ï¼š
$$
Y =\left[\begin{array}{c}y_1 \\ y_2\\ \vdots \\ y_n\end{array}\right]
$$



### æ¨¡å‹æ±‚è§£

#### æ¢¯åº¦ä¸‹é™æ³•

Gradient Decent
$$
\theta:=\theta-\alpha \nabla_{\theta} J(\theta)
$$

$$
J(\theta)=\frac{1}{2} \sum_{i=1}^{n}\left(x_{i}^{T} \theta-y_{i}\right)^{2}
$$

å…¶ä¸­ç®—å­ï¼šæ¢¯åº¦æ˜¯åå¯¼æ•°çš„è‡ªç„¶æ‰©å±•
$$
\nabla_{\theta} J=\left[\begin{array}{l}\frac{\partial J}{\partial \theta_{0}} \\ \cdots \\ \cdots  \\ \frac{\partial J}{\partial \theta_{p}}\end{array}\right]
$$
æ±‚æŸå¤±å‡½æ•°çš„åå¯¼ï¼š
$$
\begin{array}{l}\frac{\partial 1}{\theta_{j} 2}\left(x_{i}^{T} \theta-y_{i}\right)^{2} \\ =\frac{\partial 1}{\theta_{j} 2}\left(\sum_{j=0}^{p} x_{i, j} \theta_{j}-y_{i}\right)^{2} \quad x_{i}=\left(x_{i, 0}, \ldots, x_{i, p}\right)^{T} \\ =\left(\sum_{j=0}^{p} x_{i, j} \theta_{j}-y_{i}\right) \frac{\partial}{\theta_{j}}\left(\sum_{j=0}^{p} x_{i, j} \theta_{j}-y_{i}\right) \\ =\left(f\left(x_{i}\right)-y_{i}\right) x_{i, j}\end{array}
$$

#### æ­£è§„æ–¹ç¨‹æ³•

$$
\begin{aligned} J(\theta) &=\frac{1}{2}\|Y-X \theta\|^{2} \\ &=\frac{1}{2}(X \theta-Y)^{T}(X \theta-Y) \\ &=\frac{1}{2}\left(\theta^{T} X^{T} X \theta-2 Y^{T} X \theta+Y^{T} Y\right) \end{aligned}
$$

æ³¨è§£ï¼š
$$
\begin{array}{l}\frac{\partial \mathbf{x}^{T} \mathbf{B} \mathbf{x}}{\partial \mathbf{x}}=\left(\mathbf{B}+\mathbf{B}^{T}\right) \mathbf{x} \\ \frac{\partial \mathbf{x}^{T} \mathbf{a}}{\partial \mathbf{x}}=\frac{\partial \mathbf{a}^{T} \mathbf{x}}{\partial \mathrm{x}}=\text { a }\\\end{array}
$$
æˆ‘ä»¬ä»¤$B=X^TX,B^T=B\Longrightarrow (B+B^B)\theta = 2B\theta$
$$
\nabla_{\theta} J(\theta)=\frac{\partial J(\theta)}{\partial \theta}=\frac{\frac{1}{2}\left(\theta^{T} X^{T} X \theta-2 Y^{T} X \theta+Y^{T} Y\right)}{\partial \theta}=X^{T} X \theta-\left(Y^{T} X\right)^{T}=X^{T} X \theta-X^{T} Y=0\\\Longrightarrow X^{T} X \theta=X^{T} Y\theta^{*}=\left(X^{T} X\right)^{-1} X^{T}\\\Longrightarrow\theta^{*}=\left(X^{T} X\right)^{-1} X^{T} Y
$$

#### éšæœºæ¢¯åº¦ä¸‹é™æ³•

Mini-batch GD

æ¯æ¬¡åª ç”¨è®­ç»ƒé›†ä¸­çš„ä¸€ä¸ªæ•°æ®ï¼ŒæŠŠæ•°æ®åˆ†ä¸ºè‹¥å¹²ä¸ªæ‰¹ï¼ŒæŒ‰æ‰¹æ¥æ›´æ–°å‚ æ•°ã€‚ä¸€ä¸ªæ‰¹ä¸­çš„ä¸€ç»„æ•°æ®å…±åŒå†³å®šäº†æœ¬æ¬¡æ¢¯åº¦çš„æ–¹å‘ï¼Œä¸‹é™èµ· æ¥å°±ä¸å®¹æ˜“è·‘åï¼Œå‡å°‘äº†éšæœºæ€§ã€‚

ä¸€ä¸ªbacth å½¢æˆä¸€ä¸ªepochåˆ†æ‰¹æ¬¡è®­ç»ƒ

### å…¨å±€æœ€ä¼˜è§£

å½“$J(\theta)$æ˜¯å‡¸å‡½æ•°ï¼ˆå‡¹å‡½æ•°å’Œå‡¸å‡½æ•°ç»Ÿç§°å‡¸å‡½æ•°ï¼‰æ—¶ï¼ŒäºŒé˜¶å¯¼æ•°å¤§äº0,$X^TX$ä¸ºåŠæ­£å®šçŸ©é˜µ
$$
\nabla_{\theta}^{2} J(\theta)=X^{T} X
$$
å½“è®­ç»ƒæ ·æœ¬çš„æ•°ç›®nå¤§äºè®­ç»ƒæ ·æœ¬çš„ç»´åº¦ï¼ˆp+1 ä¸ªå±æ€§ï¼Œç‰¹å¾ï¼‰$X^TX$é€šå¸¸å¯é€†ï¼Œè¡¨æ˜æ”¹çŸ©é˜µäº‹æ­£å®šçŸ©é˜µï¼Œæ±‚çš„å‚æ•°æ˜¯å…¨å±€æœ€ä¼˜è§£ã€‚ä¸å¯é€†æ—¶ï¼Œå¯ä»¥æ¥å‡ºå¤šä¸ªå‚æ•°è§£ã€‚å¯ä½¿ç”¨ æ­£åˆ™åŒ–ç»™å‡ºä¸€ä¸ªâ€œå½’çº³åå¥½â€è§£ã€‚

### è¯„ä¼°æ–¹æ³•

#### ç•™å‡ºæ³•

éšæœºæŒ‘é€‰ ä¸€éƒ¨åˆ†æ ‡ è®°æ•°æ®ä½œ ä¸ºæµ‹è¯•é›† (ç©ºå¿ƒç‚¹ )ï¼Œå…¶ä½™çš„ä½œ ä¸ºè®­ç»ƒé›† (å®å¿ƒç‚¹ )ï¼Œè®¡ç®— å›å½’æ¨¡å‹ï¼Œä½¿ç”¨æµ‹è¯• é›†å¯¹æ¨¡å‹ è¯„ä¼°: MSE =2.4ï¼Œæµ‹è¯•é›†ä¸èƒ½å¤ªå¤§ï¼Œä¹Ÿä¸ èƒ½å¤ªå°ã€‚2 <= n:m <=4

#### äº¤å‰éªŒè¯æ³•

![](https://cdn.mathpix.com/snip/images/nXRmmZcFN_wIuR7Nc-faI45CWKH5hS6nU-eZ3hlYD70.original.fullsize.png)

#### æ€§èƒ½åº¦é‡

##### çº¿æ€§å›å½’æ¨¡å‹ï¼šå¹³æ–¹å’Œè¯¯å·®

åœ¨æµ‹è¯•é›†ä¸ŠæŠ¥å‘Š MSE(mean square error) è¯¯å·®
$$
J_{\text {train }}(\theta)=\frac{1}{2} \sum_{i=1}^{n}\left(\mathbf{x}_{i}^{T} \theta-y_{i}\right)^{2}
$$

$$
\theta^{*}=\operatorname{argmin} J_{\text {train }}(\theta)=\left(X_{\text {train }}^{T} X_{\text {train }}\right)^{-1} X_{\text {train }}^{T} \vec{y}_{\text {train }}
$$

$$
J_{\text {test }}=\frac{1}{m} \sum_{i=n+1}^{n+m}\left(\mathbf{x}_{i}^{T} \theta^{*}-y_{i}\right)^{2}=\frac{1}{m} \sum_{i=n+1}^{n+m} \varepsilon_{i}^{2}
$$

##### åˆ†ç±»ä»»åŠ¡ï¼šé”™è¯¯ç‡ä¸ç²¾åº¦

é”™è¯¯ç‡æ˜¯åˆ†ç±»é”™è¯¯çš„æ ·æœ¬æ•°å æ ·æœ¬æ€»æ•°çš„æ¯”ä¾‹

ç²¾åº¦æ˜¯åˆ†ç±»æ­£ç¡®çš„æ ·æœ¬æ•°å æ ·æœ¬æ€»æ•°çš„æ¯”ä¾‹

å¯¹äºŒåˆ†ç±»é—®é¢˜ï¼š

æŸ¥å‡†ç‡ï¼š$P=\frac{T P}{T P+F P}$

æŸ¥å…¨ç‡ï¼š$R=\frac{T P}{T P+F N}$

F1:
$$
F 1=\frac{2 \times P \times R}{P+R}=\frac{2 \times T P}{\text { æ ·ä¾‹æ€»æ•° }+T P-T N}
$$



## åŸºäºéçº¿å½¢åŸºçš„çº¿æ€§å›å½’

### å¤šé¡¹å¼å›å½’



# LR-é€»è¾‘å›å½’ 

## Structural model
é€»è¾‘å‡½æ•°ï¼ˆlogistic/sigmoid functionï¼‰

$$
y=\frac{1}{1+e^{-z}} = \frac{1}{1+e^{-\theta x}}
$$

## Error model
æŸå¤±å‡½æ•° Loss function 

$$
\begin{array}{c}P(y=1 \mid x ; \theta)=f_{\theta}(x)=\frac{1}{1+e^{-\theta^{T} * x}} \\ P(y=0 \mid x ; \theta)=1-f_{\theta}(x)=\frac{e^{-\theta^{T} * x}}{1+e^{-\theta^{T} * x}}\end{array}
$$


æ±‚å‚æ•°æ–¹æ³•--å¯¹$\theta$æå¤§ä¼¼ç„¶ä¼°è®¡ï¼Œä½¿å¾—yå‘ç”Ÿçš„æ¦‚ç‡æœ€å¤§
$$
L(\theta)=\prod_{i=1}^{n} P\left(y_{i} \mid x_{i} ; \theta\right)=\prod_{i=1}^{n}\left(f_{\theta}\left(x_{i}\right)\right)^{y_{i}}\left(1-f_{\theta}\left(x_{i}\right)\right)^{1-y_{i}}
$$
è½¬åŒ–ä¸ºå¯¹æ•°å‡½æ•°ï¼Œå°†$\frac{f_{\theta}(x)} {1-f_{\theta}(x)}=\frac{1}{1+e^{-\theta^{T} * x}}/\frac{e^{-\theta^{T} * x}}{1+e^{-\theta^{T} * x}} = \frac{1}{e^{-\theta x}} = e^{\theta x}$
$$
\begin{array}{l}\ln L(\theta)=\sum_{i=1}^{n}\left(y_{i} \ln \left(f_{\theta}\left(x_{i}\right)\right)+\left(1-y_{i}\right) \ln \left(1-f_{\theta}\left(x_{i}\right)\right)\right) \\ =\sum_{i=1}^{n}\left(\left(1-y_{i}\right)\left(-\theta^{T} * x_{i}\right)-\ln \left(1+e^{-\theta^{T} * x_{i}}\right)\right)\end{array}
$$
æ¢¯åº¦ä¸Šå‡
$$
\theta:=\theta+\alpha \nabla_{\theta} \ln (L(\theta)) \Leftrightarrow \theta_{j}:=\theta_{j}+\frac{\partial \ln (L(\theta))}{\partial \theta_{j}}
$$
æ±‚æ¢¯åº¦
$$
\begin{aligned} \nabla_{\theta} \ln (L(\theta)) &=\sum_{i=1}^{n}\left[-\left(1-y_{i}\right) \cdot x_{i}-\frac{1}{1+e^{-\theta^{T} x_{i}}}\left(e^{-\theta^{T} x_{i}}\right)\left(-x_{i}\right)\right] \\ &=\sum_{i=1}^{n}\left(-1+y_{i}+\frac{e^{-\theta^{T} x_{i}}}{1+e^{-\theta^{T} x_{i}}}\right) x_{i} \\ &=\sum_{i=1}^{n}\left(y_{i}-f_{\theta}\left(x_{i}\right)\right) x_{i} \Leftrightarrow \frac{\partial}{\partial \theta_{j}} \ln (L(\theta))=\sum_{i=1}^{n}\left(y_{i}-f_{\theta}\left(x_{i}\right)\right) x_{i, j} \end{aligned}
$$
ä»£å…¥æ¢¯åº¦çš„å‚æ•°æ›´æ–°
$$
\theta:=\theta+\alpha \nabla_{\theta} \ln (L(\theta)) \Rightarrow \theta:=\theta+\alpha \sum_{i=1}^{n}\left(y_{i}-f_{\theta}\left(x_{i}\right)\right) x_{i}
$$
## å’Œçº¿æ€§å›å½’çš„å¯¹æ¯”

å’Œçº¿å½¢å›å½’æ¨¡å‹çœ‹ä¼¼ä¸€æ ·ï¼Œä½†æ˜¯fä¸åŒï¼Œé€»è¾‘å›å½’è§£å†³çš„æ˜¯äºŒåˆ†ç±»é—®é¢˜

|      | é€»è¾‘å›å½’   | çº¿æ€§å›å½’ |
| ---- | ---------- | -------- |
| è¾“å‡º |            |          |
|      | çº¿å½¢äºŒåˆ†ç±» | çº¿æ€§æ‹Ÿåˆ |
|      |            |          |
|      |            |          |
|      |            |          |

# NN-ç¥ç»ç½‘ç»œ
## Structural model

### é€»è¾‘å›å½’çš„äºŒé˜¶æ®µè¡¨ç¤º

$z = b+ \sum x_iw = \mathop{W^T}\limits_{p \times 1}\mathop{x}\limits_{1\times p} + \mathop{b}\limits_{1\times1}$

$\hat y = sigmoid(z) = \frac{e^z}{1+e^z}$

### ç¥ç»å…ƒ

ç¥ç»å…ƒ=çº¿æ€§ç»„åˆ(zï¼Œæ¥æ”¶ä¿¡å·)+éçº¿æ€§æ¿€æ´»(sigmoidï¼Œ è¾“å‡ºéçº¿æ€§å†³ç­–é¢)
$$
\boldsymbol{z}_{t}=W_{1}^{T} \boldsymbol{x}
$$
å¤šç¥ç»å…ƒ

ç¥ç»ç½‘ç»œåŒ…å«å¤šä¸ªç¥ç»å…ƒï¼Œ è¾“å…¥xä¸å¤šä¸ªç¥ç»å…ƒç›¸è¿ã€‚

### ä¸€ä¸ªéšè—å±‚çš„ç¥ç»ç½‘ç»œ

$$
\boldsymbol{z}_{1}=W_{1}^{T} \boldsymbol{x}\\h_1 = sigmoid(z_1)\\z_2 = w_2^Th_1\\ \hat y = sigmoid(z_1)
$$
Wè¡¨ç¤ºXçš„ç¬¬jä¸ªå…ƒç´ ä¸å‘é‡Zçš„ç¬¬iä¸ªå…ƒç´ ä¹‹é—´çš„é“¾æ¥æƒé‡
$$
W=\left[\begin{array}{llll}W_{11} & W_{21} & W_{31} & W_{41} \\ W_{12} & W_{22} & W_{32} & W_{42} \\ W_{13} & W_{23} & W_{33} & W_{43}\end{array}\right]
$$

$$
\mathrm{W}^{T}=\left[\begin{array}{lll}W_{11} & W_{12} & W_{13} \\ W_{21} & W_{22} & W_{23} \\ W_{31} & W_{32} & W_{33} \\ W_{41} & W_{42} & W_{43}\end{array}\right]
$$

éšå«å±‚h
æ²¡æœ‰éšå«å±‚å°±åªéœ€è¦ä¸€ä¸ªåˆ—å‘é‡ï¼Œå› ä¸ºæœ‰éšå«å±‚æ‰€ä»¥éœ€è¦WçŸ©é˜µ
æ¯ä¸€å±‚è®¡ç®—å°±æ˜¯çº¿æ€§ç»„åˆ+éçº¿å½¢æ¿€æ´»

### éçº¿å½¢æ¿€æ´»å‡½æ•°

å¼•å…¥éçº¿æ€§æ¿€æ´»å‡½æ•°çš„ç›®çš„æ˜¯å¾—åˆ°éçº¿æ€§å†³ç­–é¢ï¼Œéçº¿å½¢æ¿€æ´»å‡½æ•°å¯ä»¥é€¼è¿‘ä»»ä½•å¤æ‚çš„å‡½æ•°ï¼Œä¸è®ºç½‘ç»œå¤šæ·±ï¼Œçº¿å½¢å‡½æ•°åªèƒ½è¾“å‡ºçº¿æ€§å†³ç­–é¢ã€‚

éçº¿å½¢æ¿€æ´»å‡½æ•°
Reluæ•ˆæœæœ€å¥½ï¼Œå› ä¸ºæœ‰éƒ¨åˆ†å¯¼æ•°ä¸º0ï¼Œæœ‰äº›ä¸º1ï¼Œä¸º0çš„éƒ¨åˆ†å¯ä»¥è®©æœ‰äº›ç¥ç»å…ƒåœæ­¢å­¦ä¹ ï¼Œèµ·åˆ°dropoutçš„ä½œç”¨ï¼Œå¯ä»¥æœ‰æ•ˆé˜²æ­¢è¿‡æ‹Ÿåˆã€‚

binary step
$$
f(x)=\left\{\begin{array}{lll}0 & \text { for } & x<0 \\ 1 & \text { for } & x \geq 0\end{array}\right.
$$
Logistic
$$
f(x)=\frac{1}{1+e^{-x}}
$$
Tanh
$$
f(x)=\tanh (x)=\frac{2}{1+e^{-2 x}}-1
$$
ReLU
$$
f(x)=\left\{\begin{array}{lll}0 & \text { for } & x<0 \\ x & \text { for } & x \geq 0\end{array}\right.
$$

### å¤šåˆ†ç±»ç¥ç»ç½‘ç»œ

<img src="/Users/wangjing/Library/Application Support/typora-user-images/image-20211019140804340.png" alt="image-20211019140804340" style="zoom:45%;" />
$$
\begin{array}{l}\boldsymbol{z}_{1}=\boldsymbol{W}_{1}^{T} \boldsymbol{x} \\ h_{1}=\operatorname{sigmoid}\left(z_{1}\right) \\ z_{2}=\boldsymbol{W}_{2}^{T} h_{1} \\ h_{2}=\operatorname{sigmoid}\left(z_{2}\right) \\ \boldsymbol{z}_{3}=w_{3}^{T} h_{2} \\ \hat{y}=\operatorname{sigmoid}\left(z_{3}\right)\end{array}
$$
$h_1$è¡¨ç¤ºhidden layer 1 output

Hidden layer(éšå±‚)çš„ä¸ªæ•°å¤§äº1çš„ç¥ç»ç½‘ç»œï¼Œç§°ä¸ºæ·±åº¦ç¥ç»ç½‘ç»œ

## Error model

éæ­£ç¡®é¢„æµ‹å¯¼è‡´çš„ä»£ä»·

### Loss function

äº¤å‰ç†µå‡½æ•°ï¼ˆcross entropy lossï¼‰

#### äºŒåˆ†ç±»æŸå¤±

é€»è¾‘å›å½’ä¸­ï¼Œä½¿ç”¨å¯¹æ•°ä¼¼ç„¶åº¦é‡æŸå¤±(æ¯ä¸ªæ ·æœ¬å±äºå…¶çœŸå® æ ‡è®°çš„æ¦‚ç‡è¶Šå¤§è¶Šå¥½)
$$
\begin{aligned} E=\operatorname{loss} &=-\log P(\mathrm{Y}=\hat{y} \mid \mathbf{X}=\boldsymbol{x}) \\ &=-y \log (\hat{y})-(1-y) \log (1-\hat{y}) \end{aligned}
$$

#### å¤šåˆ†ç±»æŸå¤±

##### Softmaxå‡½æ•°

(æŸ”æ€§ æœ€å¤§å€¼):å°†è¾“å‡ºå€¼è½¬åŒ–æˆæ¦‚ç‡ã€‚
$$
\hat{y}_{i}=\frac{e^{z_{i}}}{\sum_{j=1}^{K} e^{z_{j}}}=\mathrm{P}\left(y_{i}=1 \mid \mathrm{x}\right)
$$
$y_j$ä¸ºone-hot å‘é‡,çœŸå®æ ‡ç­¾ä½ç½®1å…¶ä»–ä½ç½®ä¸º0
$$
E=\operatorname{loss}=-\sum_{j=1 . K} y_{j} \log \hat{y}_{j}
$$

#### å›å½’æŸå¤±

ä¸åˆ†ç±»ç½‘ç»œä¸åŒï¼šè¾“å‡ºå±‚ï¼ˆæœ€åä¸€å±‚ï¼‰ä¸å†åŒ…å«sigmoidå‡½æ•°

##### äºŒæ¬¡ä»£ä»·å‡½æ•°

$$
\begin{array}{l}E=\operatorname{Los} s=\frac{1}{2}\|y-\hat{y}\|^{2} \\ =\frac{1}{2} \sum_{j=1}^{K}\left(y_{j}-\hat{y}_{j}\right)^{2}\end{array}
$$

## æ¨¡å‹å»ºæ¨¡

ä¼˜åŒ–å‚æ•°ç›®æ ‡:å¯»æ‰¾ä½¿æŸå¤±è¾¾åˆ°æœ€å°çš„ç¥ç»ç½‘ç»œæƒé‡
$$
\mathrm{W}^{*}=\underset{W}{\operatorname{argmin}} E(\hat{y} ; \mathrm{W})
$$
å¦‚ä½•å­¦ä¹ å®ç°ç›®æ ‡çš„ç¥ç»ç½‘ç»œæƒé‡ğ‘Š --æ¢¯åº¦ä¸‹é™
$$
W_{L}(t+1)=W_{L}(t)-\eta \frac{\partial E}{\partial W_{L}(t)}
$$
### åå‘ä¼ æ’­

æ±‚åå¯¼ä»è€Œåº”ç”¨æ¢¯åº¦ä¸‹é™

1. é‡å¤åº”ç”¨å¾®ç§¯åˆ†çš„é“¾å¼æ³•åˆ™
2. å±€éƒ¨æœ€å°åŒ–ç›®æ ‡å‡½æ•°
3. è¦æ±‚ç½‘ç»œæ‰€æœ‰çš„â€œå—â€(blocks)éƒ½æ˜¯å¯å¾®çš„

```
æ­£å‘è®¡ç®—--èŠ‚ç‚¹
åå‘æ±‚å¯¼--è¾¹ é“¾å¼æ³•åˆ™ä»åå¾€å‰æ±‚
```

#### åå‘ä¼ æ’­--å›å½’å®ä¾‹

å›å½’æŸå¤±å‡½æ•°ä¸ºäºŒæ¬¡ä»£ä»·å‡½æ•°
$$
E = loss = \frac{1}{2}(y-\hat y)^2
$$

#### åå‘ä¼ æ’­--äºŒåˆ†ç±»å®ä¾‹

äºŒåˆ†ç±»æŸå¤±å‡½æ•°ä¸ºäº¤å‰ç†µæŸå¤±å‡½æ•°
$$
\text { Loss }=-y \ln (\widehat{y})-(1-y) \ln (1-\widehat{y})
$$
é€šè¿‡æ¢¯åº¦ä¸‹é™ æœ€å°åŒ–Loss
$$
\begin{array}{l}w_{2}(t+1)=w_{2}(t)-\eta \frac{\partial E}{\partial w_{2}(t)} \\ W_{1}(t+1)=W_{1}(t)-\eta \frac{\partial E}{\partial W_{1}(t)}\end{array}
$$

å‡½æ•°å…³äºä¸€ä¸ªçŸ©é˜µæ±‚åå¯¼-->å¯¹æ¯ä¸€ä¸ªå…ƒç´ æ±‚åå¯¼,$W_{11}^1$è¡¨ç¤ºè¾“å…¥xçš„ç¬¬jä¸ªå…ƒç´ åˆ°ç¬¬ä¸€ä¸ªéšå±‚çš„ç¬¬iä¸ªç¥ç»å…ƒçš„æƒé‡
$$
\begin{aligned} E=&-y \ln (\hat{y}) -(1-y) \ln (1-\hat{y}) \\ \hat{y}=& \frac{e^{z_{2}}}{1+e^{z_{2}}} \\ z_{2}=& \boldsymbol{w}_{2}^{T} \boldsymbol{h}_{1} \\ \boldsymbol{h}_{1}=& \frac{e^{z_{1}}}{1+e^{z_{1}}} \\ \boldsymbol{z}_{1}=& W_{1}^{T} \boldsymbol{x} \end{aligned}
$$

$$
\frac{\partial E}{\partial \boldsymbol{W}_{1}}=\frac{\partial E}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial z_{2}} \cdot \mid \frac{\partial z_{2}}{\partial \boldsymbol{h}_{1}} \cdot \frac{\partial \boldsymbol{h}_{1}}{\partial \boldsymbol{z}_{1}} \cdot \frac{\partial \boldsymbol{z}_{1}}{\partial W_{1}}
$$

**Hadamard (å“ˆè¾¾ç›)ä¹˜ç§¯ /schur ä¹˜ç§¯**
å‡è®¾ ğ‘ å’Œğ‘¡æ˜¯ä¸¤ä¸ªåŒæ ·ç»´åº¦çš„å‘é‡ï¼Œä½¿ç”¨ğ‘  âˆ˜ ğ‘¡(æˆ–ğ‘  âŠ™ ğ‘¡)æ¥è¡¨ç¤ºæŒ‰å…ƒç´ çš„ä¹˜ç§¯: $(ğ‘ âŠ™ğ‘¡) =s_jt_j$
$$
\left[\begin{array}{l}1 \\ 2\end{array}\right] \odot\left[\begin{array}{l}3 \\ 4\end{array}\right]=\left[\begin{array}{l}1 * 3 \\ 2 * 4\end{array}\right]=\left[\begin{array}{l}3 \\ 8\end{array}\right]
$$

**åå‘ä¼ æ’­çš„å±€éƒ¨æ€§**

åå‘ä¼ æ’­çš„ä¸€èˆ¬æƒ…å½¢
ç¬¬ğ‘™å±‚ç¬¬ğ‘—ä¸ªç¥ç»å…ƒå’Œç¬¬ğ‘™ âˆ’ 1 å±‚ç¥ç»å…ƒä¹‹é—´å…³ç³»
$$
z_{j}^{l}=\sum_{k=1} w_{j k}^{l-1} h_{k}^{l-1}+b_{j}^{l-1}
$$

#### åå‘ä¼ æ’­çš„ä¸€èˆ¬æƒ…å½¢

ä¸€äº›å®šä¹‰

$\delta_{j}^{l}: \quad \delta_{j}^{l} \equiv \frac{\partial E}{\partial z_{j}^{l}}$ï¼Œç§°ä¸ºåœ¨ç¬¬ğ‘™å±‚ç¬¬ğ‘—ä¸ªç¥ç»å…ƒçš„è¯¯å·®
$$
\begin{array}{l}z_{j}^{l}=\sum_{k=1} w_{j k}^{l-1} h_{k}^{l-1}+b_{j}^{l-1} \\ h_{j}^{l}=\sigma\left(z_{j}^{l}\right) \\ \sigma(x)=\frac{1}{1+e^{-x}}\end{array}
$$
çŸ©é˜µè¡¨è¾¾å½¢å¼--ä»£ä»·å‡½æ•°

$$
E=\frac{1}{2}\left\|\boldsymbol{y}-\boldsymbol{h}^{L}\right\|^{2}=\frac{1}{2}\|\boldsymbol{y}-\widehat{\boldsymbol{y}}\|^{2}
$$
ç¬¬ğ‘™å±‚ç¬¬ğ‘—ä¸ªç¥ç»å…ƒå’Œç¬¬ğ‘™ âˆ’ 1å±‚ç¥ç»å…ƒä¹‹é—´çš„å…³ç³»:
$$
z_{j}^{l}=\sum_{k=1} w_{j k}^{l-1} h_{k}^{l-1}+b_{j}^{l-1}, \quad h_{j}^{l}=\sigma\left(z_{j}^{l}\right)
$$



### ğŸ®åå‘ä¼ æ’­å››ä¸ªæ–¹ç¨‹

#### BP1

è¾“å‡ºå±‚ï¼ˆæœ€åä¸€å±‚ï¼Œå³ä¸ºLå±‚ï¼‰è¯¯å·®çš„æ–¹ç¨‹
$$
E=\frac{1}{2}\left\|\boldsymbol{y}-\boldsymbol{h}^{L}\right\|^{2}=\frac{1}{2} \sum_{j=1}^{K}\left(h_{j}^{L}-y_{j}\right)^{2}
$$
ç¬¬Lå±‚ç¬¬jä¸ªç¥ç»å…ƒçš„è¯¯å·®
$$
\delta_{j}^{L}=\frac{\partial E}{\partial z_{j}^{L}}=\frac{\partial E}{\partial h_{j}^{L}} \frac{\partial h_{j}^{L}}{\partial z_{j}^{L}}=\left(h_{j}^{L}-y_{j}\right) \sigma^{\prime}\left(z_{j}^{L}\right)
$$
å‘é‡è¡¨è¾¾å½¢å¼ï¼š
$$
ğ›¿_ğ¿=(ğ’‰^ğ¿âˆ’ğ‘¦)\odotğœ^{'}(ğ’›^ğ¿)
$$

#### BP2

æ¯ä¸€å±‚çš„è¯¯å·®ï¼Œä½¿ç”¨ä¸‹ä¸€å±‚çš„è¯¯å·® $\delta^{l+1} $è¡¨ç¤ºå½“å‰å±‚çš„è¯¯å·® $\delta^l $:
$$
\delta^{l}=\sigma^{\prime}\left(\mathbf{z}^{l}\right) \odot\left(\boldsymbol{W}^{l} \delta^{l+1}\right)
$$



#### BP3

ä»£ä»·å‡½æ•°å…³äºåç½®bçš„åå¯¼

#### BP4

ä»£ä»·å‡½æ•°å…³äºæƒé‡çš„åå¯¼

#### Summary

å‘é‡å½¢å¼ï¼š
$$
\begin{array}{l}\text { (BP1) } \delta^{L}=\left(\boldsymbol{h}^{L}-y\right) \odot \sigma^{\prime}\left(\mathbf{z}^{L}\right)\\ \text { (BP2) } \delta^{l}=\sigma^{\prime}\left(\mathbf{z}^{l}\right) \odot\left(\boldsymbol{W}^{l} \delta^{l+1}\right) \\ \text { (BP3) } \frac{\partial E}{\partial b^{l-1}}=\delta^{l} \\ \text { (BP4) } \frac{\partial E}{\partial W^{l-1}}=\boldsymbol{h}^{l-1}\left(\delta^{l}\right)^{T}\end{array}
$$

æ•°å­¦å½¢å¼ï¼š
$$
BP1:& \delta_{j}^{L}=\left(h_{j}^{L}-y_{j}\right) \sigma^{\prime}\left(z_{j}^{L}\right)\\BP2:&\delta_{j}^{l}=\sum_{k=1} \delta_{k}^{l+1} w_{k j}^{l} \sigma^{\prime}\left(z_{j}^{l}\right)\\BP3:&\frac{\partial E}{\partial b_{j}^{l-1}}=\delta_{j}^{l}\\BP4:&\frac{\partial E}{\partial w_{j k}^{l-1}}=h_{k}^{l-1} \delta_{j}^{l}
$$

åå‘ä¼ æ’­ç®—æ³•
1. è¾“å…¥xï¼šä¸ºè¾“å…¥å±‚è®¾ç½®å¯¹åº”çš„æ¿€æ´»å€¼h1
2. å‰å‘ä¼ æ’­ï¼šçº¿æ€§ç»„åˆ+éçº¿å½¢æ¿€æ´»
3. è¾“å‡ºå±‚è¯¯å·®å’Œåå‘è¯¯å·®ä¼ æ’­ï¼šBP1å’ŒBP2
4. è¾“å‡ºï¼šè¯¯å·®å‡½æ•°çš„æ¢¯åº¦ç”±BP3å’ŒBP4ç»™å‡º


## æ¨¡å‹æ”¹è¿›

### æ”¹è¿›æŸå¤±å‡½æ•°

å¯¹æ•°ä¼¼ç„¶

#### æŸå¤±å‡½æ•°å¯¹æ¯”
äº¤å‰ç†µVSäºŒæ¬¡ä»£ä»·å‡½æ•°

|               | äºŒæ¬¡ä»£ä»·å‡½æ•°                                                 | äº¤å‰ç†µ                                                       |
| ------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| å‡½æ•°è¡¨è¾¾å¼    | $E = \frac{1}{2}(y-\hat y)^2$                                | $E = -yln\hat y-(1-y)ln(1-\hat y)$                           |
|               |                                                              |                                                              |
|               |                                                              |                                                              |
| å¯¹å‚æ•°wåå¯¼   | $\frac{\partial E}{\partial w}=(\hat{y}-y) \sigma^{\prime}(z) x=(\sigma(z)-y) \sigma^{\prime}(z) x$ | $\frac{\partial E}{\partial w}=(\hat{y}-y) x=(\sigma(z)-y) x$ |
| å¯¹å‚æ•°bçš„æ±‚å¯¼ | $\frac{\partial E}{\partial b}=(\hat{y}-y) \sigma^{\prime}(z)=(\sigma(z)-y) \sigma^{\prime}(z)$ | $\frac{\partial E}{\partial b}=(\hat{y}-y)=(\sigma(z)-y)$    |

### æƒé‡åˆå§‹åŒ–å»ºè®®

éšæœºåˆå§‹åŒ–:ä½¿ç”¨Numpyçš„ np.random.randnå‡½æ•°ç”Ÿæˆå‡ å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1çš„é«˜æ–¯åˆ†å¸ƒã€‚

æ”¹è¿›:å¯¹äºä»»æ„ğ‘™å±‚ï¼Œä½¿ç”¨å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1 çš„é«˜æ–¯åˆ†å¸ƒéšæœºåˆ†å¸ƒåˆå§‹åŒ–æƒé‡å‚æ•°ğ‘Šğ‘™âˆ’1ï¼Œğ‘ğ‘™âˆ’1ã€‚æ­¤æ—¶ä¸­é—´å˜é‡ğ‘§ğ‘™ æœä»å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1çš„é«˜æ–¯åˆ†å¸ƒã€‚

###  å‡å°‘è¿‡æ‹Ÿåˆ:dropout 

1. éšæœºåœ°åˆ é™¤ç½‘ç»œä¸­çš„ä¸€åŠçš„éšè—ç¥ç»å…ƒï¼ŒåŒæ—¶è®©è¾“å…¥å±‚å’Œè¾“å‡ºå±‚çš„ç¥ç»å…ƒä¿æŒä¸å˜ã€‚
2. æŠŠè¾“å…¥xé€šè¿‡ä¿®æ”¹åçš„ç½‘ç»œå‰å‘ä¼ æ’­ï¼Œç„¶åæŠŠå¾—åˆ°çš„æŸå¤±ç»“ æœé€šè¿‡ä¿®æ”¹çš„ç½‘ç»œåå‘ä¼ æ’­ã€‚åœ¨mini-batch ä¸Šæ‰§è¡Œå®Œè¿™ä¸ªè¿‡ ç¨‹åï¼Œåœ¨æ²¡æœ‰è¢«åˆ é™¤çš„ç¥ç»å…ƒä¸Šæ›´æ–°å¯¹åº”çš„å‚æ•°(wï¼Œb)
3. ç»§ç»­é‡å¤ä¸Šè¿°è¿‡ç¨‹:
	- æ¢å¤è¢«åˆ æ‰çš„ç¥ç»å…ƒ(æ­¤æ—¶è¢«åˆ é™¤çš„ç¥ç»å…ƒä¿æŒåŸæ ·ï¼Œ è€Œæ²¡æœ‰è¢«åˆ é™¤çš„ç¥ç»å…ƒå·²ç»æœ‰æ‰€æ›´æ–°)
	- ä»éšè—å±‚ç¥ç»å…ƒä¸­éšæœºé€‰æ‹©ä¸€ä¸ªä¸€åŠå¤§å°çš„å­é›†ä¸´æ—¶ åˆ é™¤æ‰(å¤‡ä»½è¢«åˆ é™¤ç¥ç»å…ƒçš„å‚æ•°)ã€‚
	- å¯¹ä¸€å°æ‰¹è®­ç»ƒæ ·æœ¬ï¼Œå…ˆå‰å‘ä¼ æ’­ç„¶ååå‘ä¼ æ’­æŸå¤±å¹¶ æ›´æ–°å‚æ•°(wï¼Œb) (æ²¡æœ‰è¢«åˆ é™¤çš„é‚£ä¸€éƒ¨åˆ†å‚æ•°å¾—åˆ° æ›´æ–°ï¼Œåˆ é™¤çš„ç¥ç»å…ƒå‚æ•°ä¿æŒè¢«åˆ é™¤å‰çš„ç»“æœ)ã€‚

### ç¼“è§£æ¢¯åº¦æ¶ˆå¤±:ReLU

å½“ğ‘§ æ˜¯è´Ÿæ•°çš„æ—¶å€™ï¼Œæ¢¯åº¦ä¸º0ï¼Œç¥ç»å…ƒåœæ­¢å­¦ä¹ (ç±»ä¼¼äº dropoutä½œç”¨ï¼Œå‡å°‘è¿‡æ‹Ÿåˆ);å½“ğ‘§å¤§äº0æ—¶ï¼Œæ¢¯åº¦ä¸º1ï¼Œå¯ ä»¥ç¼“è§£ä¸‹æº¢é—®é¢˜



# SVM-æ”¯æŒå‘é‡æœº

## çº¿å½¢å¯åˆ†-SVM

çº¦æŸä¼˜åŒ–é—®é¢˜

1. ç›®æ ‡å‡½æ•° $minf(x)$

2. å˜é‡

3. çº¦æŸæ¡ä»¶
   $$
   \begin{array}{lllll}\text { s.t. } & g_{j}(x)=0, & j=1, & 2, & \cdots & n \\ & h_{i}(x) \leq 0, & i=1, & 2, & \cdots, & m\end{array}
   $$

æ±‚è§£æ–¹æ³•---æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•
$$
L(x, \lambda, \alpha)=f(x)+\sum_{j} a_{j} g_{j}(x)+\sum_{i} \lambda_{i} h_{i}(x)
$$

$$
\frac{\partial L}{\partial x} = \nabla f\left(x^{*}\right)+\sum_{i} a_{j} \nabla g_{j}\left(x^{*}\right)+\sum_{i} \lambda_{i} \nabla h_{i}\left(x^{*}\right)=0
$$

$$
\begin{array}{l}\nabla_{\mathbf{x}} L=\frac{\partial L}{\partial \mathbf{x}}=\nabla f+\lambda \nabla g=\mathbf{0} \\ \nabla_{\lambda} L=\frac{\partial L}{\partial \lambda}=g(\mathbf{x})=0\end{array}
$$
è®¡ç®— L å¯¹ x ä¸ $\lambda$ çš„åå¯¼æ•°å¹¶è®¾ä¸ºé›¶ï¼Œå¯å¾—æœ€ä¼˜è§£çš„å¿…è¦æ¡ä»¶
å¦‚ä½•ç†è§£KKTï¼Ÿ

Karush-Kuhn-Tucker (KKT)æ¡ä»¶

éçº¿æ€§è§„åˆ’æœ€ä½³è§£çš„å¿…è¦æ¡ä»¶--KKTæ¡ä»¶å°†Lagrangeä¹˜æ•°æ³•æ‰€å¤„ç†æ¶‰åŠç­‰å¼çš„çº¦æŸä¼˜åŒ–é—®é¢˜æ¨å¹¿è‡³ä¸ç­‰å¼
$$
\begin{array}{c}\nabla f\left(x^{*}\right)+\sum_{j} a_{j} \nabla g_{j}\left(x^{*}\right)+\sum_{i} \lambda_{i} \nabla h_{i}\left(x^{*}\right)=0 \\ g_{j}\left(x^{*}\right)=0 \\ h_{i}\left(x^{*}\right) \leq 0, \lambda_{i} \geq 0, \lambda_{i} h_{i}\left(x^{*}\right)=0\end{array}
$$
### å¯¹å¶é—®é¢˜
$$
\max _{\alpha_{i} \geq 0} \min _{w} L(w, \alpha)
$$
$$
f_{0}(w) = \max _{\alpha_{i} \geq 0} L(w, \alpha)\\
f_{0}(w) > L(w, \alpha)
$$

ç®€å•çš„ä¾‹å­
$$
\begin{array}{l}\min _{u} u^{2} \\ \text { s.t. } u>=b\end{array}
$$
ä½¿ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•å°†å…¶è½¬åŒ–ä¸º
$$
L = u^2 + \lambda (u-b) \\
\frac{\partial L}{\partial u} = 2u + \lambda
\\ u-b = 0 
\\u = b
\\\lambda = 2b
$$

### Marginæ¨¡å‹

<img src="/Users/wangjing/Library/Application Support/typora-user-images/image-20211116103423027.png" alt="image-20211116103423027" style="zoom:50%;" />

åˆ†ç±»é¢ï¼š
$$
w^{T} x+b=0
$$
+1æ”¯æŒé¢ï¼š
$$
w^{T} x+b = 1
$$
-1æ”¯æŒé¢ï¼š
$$
w^{T} x+b=-1
$$
å‘é‡ w ä¸æ”¯æŒé¢ã€åˆ†ç±»é¢æ­£äº¤
$$
\left.\begin{array}{l}w^{T} x_{1}+b=1 \\ w^{T} x_{2}+b=1\end{array}\right\} \Rightarrow w^{T}\left(x_{1}-x_{2}\right)=0
$$
ä½¿ç”¨ w å’Œ b å¯¹ M å»ºæ¨¡
$$
\left.\begin{array}{l}w^{T} x^{+}+b=+1 \\ w^{T} x^{-}+b=-1\end{array}\right\} \Rightarrow w^{T}\left(x^{+}-x^{-}\right)=2
$$
å¾—åˆ°ä¸¤ä¸ªæ”¯æ’‘é¢æœ€å¤§é—´éš”
$$
\operatorname{margin} M=\left\|x^{+}-x^{-}\right\|=\frac{2}{\|w\|}
$$

### åˆ†ç±»æ¨¡å‹

ç›®æ ‡å‡½æ•°ï¼šé—´éš”æœ€å¤§ ï¼ˆäºŒæ¬¡å‡½æ•°ï¼‰


$$
\max \left(\frac{2}{\|w\|}\right) \Leftrightarrow \min \left(\|w\|^{2}\right) \\ \min _{\boldsymbol{w}, b} \boldsymbol{w}^{T} \boldsymbol{w} / 2
$$
çº¦æŸ:çº¿å½¢çº¦æŸ
$$
\left\{\begin{array}{ll}\boldsymbol{w}^{T} \boldsymbol{x}_{i}+b \geq 1 & y_{i}=1 \\ \boldsymbol{w}^{T} \boldsymbol{x}_{i}+b \leq-1 & y_{i}=-1\end{array}\right.
$$
çº¦æŸå¯åˆå¹¶ä¸ºï¼š
$$
y_{i}\left(\boldsymbol{w}^{T} x_{i}+b\right) \geq 1
$$

## SVM--è¿›é˜¶

### çº¿å½¢ä¸å¯åˆ†SVM-è½¯-SVM

æ–°çš„ä¼˜åŒ–é—®é¢˜
$$
\min _{w, b} w^{T} w / 2+C \sum_{i=1}^{n} \epsilon_{i}
$$
çº¦æŸï¼š
$$
\begin{array}{c}y_{i}\left(w^{T} x_{i}+b\right) \geq 1-\epsilon_{i} \\ \epsilon_{i} \geq 0\end{array}
$$
è½¯-SVMå¯¹å¶é—®é¢˜
$$
\begin{array}{l}\max _{\alpha} \sum_{i} \alpha_{i}-\frac{1}{2} \sum_{i, j} \alpha_{i} \alpha_{j} y_{i} y_{j} \mathbf{x}_{i}^{T} \mathbf{x}_{j} \\ \sum_{i} \alpha_{i} y_{i}=0 \\ C \geq \alpha_{i} \geq 0, \forall i\end{array}
$$
ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•è½¬åä¸ºæ— çº¦æŸé—®é¢˜ï¼š
$$
L=\frac{1}{2}\|w\|^{2}+C \sum_{i=1}^{n} \epsilon_{i}-\sum_{i=1}^{n} \alpha_{i}\left(y_{i}\left(w^{T} x_{i}+b\right)-1+\epsilon_{i}\right)-\sum_{i=1}^{n} \mu_{i} \epsilon_{i}
$$

$$
\frac{\partial L}{\partial w} = 0 \\
\frac{\partial L}{\partial \alpha} = 0 \\
\frac{\partial L}{\partial \mu} = 0
$$

æ”¯æŒå‘é‡æœ‰ä¸¤ç±»ï¼š

1. æ”¯æŒé¢ä¸Šçš„ç‚¹
2. è¿èƒŒç¡¬çº¦æŸæ ·æœ¬ç‚¹

### éçº¿å½¢-æ ¸SVM

æ¨¡å‹ï¼š

1. åˆ©ç”¨éçº¿æ€§æ˜ å°„æŠŠåŸå§‹æ•°æ®æ˜ å°„åˆ°é«˜ç»´ç©ºé—´ä¸­$\phi(x)$
2. ç›®æ ‡å‡½æ•°

$$
\begin{array}{l}\min w^{T} w / 2 \\ \text { s.t. } y_{i}\left(w^{T} \phi\left(x_{i}\right)+b\right) \geq 1\end{array}
$$

### å¤šåˆ†ç±»SVM

1. ä¸€å¯¹å¤šone-verus-rest

ä¸€ç§æ­£æ ·æœ¬ï¼Œå¤šç§è´Ÿæ ·æœ¬

ä¼šå‡ºç°æ•°æ®ä¸å¹³è¡¡ï¼Œåˆ†ç±»é¢åç½®
$$
\hat y \leftarrow argmaxw_k x + b_k
$$
æ”¹è¿›ï¼šæœŸæœ›æ­£ç±»å’Œè´Ÿç±»ä¹‹é—´çš„é”™è¯¯è¾¾åˆ°å¹³è¡¡
$$
\begin{array}{c}\min w^{T} w / 2+\mathrm{C}\left(\frac{N}{N_{+}} \sum_{i: y_{i}=+1} \epsilon_{i}+\frac{N}{N_{-}} \sum_{i: y_{i}=-1} \epsilon_{i}\right) N=N_{+}+N_{-} \\ \text {s.t. } \quad y_{i}\left(w^{T} x_{i}+b\right) \geq 1-\epsilon_{i} \\ \epsilon_{i} \geq 0\end{array}
$$

2. å¤šä¸ª1V1 one-verus-one è®­ç»ƒ $\frac{m(m-1)}{2}$ä¸ªåˆ†ç±»å™¨

æ ·æœ¬é‡è¾ƒå°‘ï¼Œåˆ†ç±»å™¨æ•°é‡æ›´å¤šï¼Œæµ‹è¯•æˆæœ¬é«˜



## ğŸ‘SVR æ”¯æŒå‘é‡å›å½’

ç»“è®ºï¼š

åˆ©ç”¨KKTæ¡ä»¶ï¼š
$$
\left\{\begin{array}{c}\alpha_{i}\left(y_{i}-f\left(x_{i}\right)-\epsilon-\xi_{i}\right)=0 \\ \hat{\alpha}_{i}\left(f\left(x_{i}\right)-y_{i}-\epsilon-\hat{\xi}_{i}\right)=0 \\ \xi_{i}\left(C-\alpha_{i}\right)=0 \\ \hat{\xi}_{i}\left(C-\hat{\alpha}_{i}\right)=0\end{array}\right.
$$

1. å½“0 < ğ›¼ğ‘– < ğ¶, ğ‘¥ğ‘–è½åœ¨é—´éš”å¸¦ä¸Šè¾¹ç•Œ
2. å½“ğ›¼ğ‘– = ğ¶ æ—¶ï¼Œğ‘¥ğ‘– è½åœ¨é—´éš”å¸¦ä¸Šè¾¹ç•Œå¤–ä¾§
3. å½“0 < ğ›¼ğ‘– < ğ¶ï¼Œğ‘¥ğ‘–è½åœ¨é—´éš”å¸¦ä¸‹è¾¹ç•Œ
4. å½“ğ›¼ğ‘– = ğ¶ æ—¶ï¼Œğ‘¥ğ‘– è½åœ¨é—´éš”å¸¦ä¸‹è¾¹ç•Œå¤–ä¾§
5. å½“ğ›¼ğ‘– = ğ›¼ğ‘– = 0æ—¶ï¼Œç‚¹è½åœ¨é—´éš”å¸¦å†…ä¾§



# ç‰¹å¾é€‰æ‹©å’Œç¨€ç–å­¦ä¹ 

## ç‰¹å¾é€‰æ‹©
## è¿‡æ»¤å¼é€‰æ‹©
(Filter method)
å•å˜é‡(Univariate)è¿‡æ»¤æ–¹æ³•:Signal-to-noise ratio (S2N)
$$
\mathrm{S} 2 \mathrm{~N}=\frac{|\mu+-\mu-|}{\sigma^{+}+\sigma-}
$$
å¤šå˜é‡(Multivariate)è¿‡æ»¤æ–¹æ³•:Relief

ç»™å®šè®­ç»ƒé›† ğ‘¥ ,ğ‘¦ ,..., ğ‘¥ ,ğ‘¦ ,

1ã€å¯¹æ¯ä¸ªæ ·æœ¬ ğ‘¥ğ‘–ï¼Œåœ¨åŒç±»æ ·æœ¬ä¸­æ‰¾æœ€è¿‘é‚» ğ‘¥ğ‘–,hğ‘–ğ‘¡;åœ¨å¼‚ç±»æ ·æœ¬ä¸­å¯»æ‰¾æœ€è¿‘é‚» ğ‘¥ğ‘–,ğ‘šğ‘–ğ‘ ğ‘ 

2ã€è®¡ç®—å¯¹åº”äºå±æ€§ ğ‘— çš„ç»Ÿè®¡é‡
$$
\delta^{j}=\sum_{i}-\operatorname{diff}\left(x_{i}^{j}, x_{i, h i t}^{j}\right)^{2}+\operatorname{diff}\left(x_{i}^{j}, x_{i, m i s s}^{j}\right)^{2}
$$
3ã€è‹¥ğ›¿ğ‘—å¤§äºæŒ‡å®šé˜ˆå€¼ğœï¼Œé€‰æ‹©å±æ€§ğ‘—;æˆ–è€…æŒ‡å®šä¸€ä¸ªkå€¼ï¼Œé€‰æ‹©ç»Ÿè®¡é‡æœ€å¤§çš„å‰k ä¸ªç‰¹å¾



## åŒ…è£¹å¼é€‰æ‹©

(Wrapper method) 

å°†æ‰€æœ‰å±æ€§ä½œä¸ºä¸€ä¸ªé›†åˆï¼Œæ¯æ¬¡ä»ä¸­é€‰å‡ºéƒ¨åˆ†ä½œä¸ºè®­ç»ƒç‰¹å¾ã€‚

NPéš¾é—®é¢˜

å¯»æ‰¾æœ€ä¼˜å­é›†

éªŒè¯é›†ï¼šé€‰è¶…å‚



## ğŸ‘åµŒå…¥å¼é€‰æ‹©--æ­£åˆ™åŒ–

(Embedded method)

L1æ­£åˆ™åŒ–
$$
E=\frac{1}{2 n} \sum_{x}\left\|\boldsymbol{y}^{x}-\boldsymbol{h}^{x, L}\right\|^{2}+\frac{\eta}{2 n} \sum_{l}\left\|w^{l}\right\|_{1}
$$
L2æ­£åˆ™åŒ–
$$
E=\frac{1}{2 n} \sum_{x}\left\|y^{x}-h^{x, L}\right\|^{2}+\frac{\eta}{2 n} \sum_{l}\left\|w^{l}\right\|_{2}^{2}
$$
æ··åˆæ­£åˆ™åŒ–
$$
E=\frac{1}{2 n} \sum_{x}\left\|\boldsymbol{y}^{x}-\boldsymbol{h}^{x, L}\right\|^{2}+\frac{\beta}{2 n} \sum_{l}\left\|W^{l}\right\|_{1}+\frac{\eta}{2 n} \sum_{l}\left\|W^{l}\right\|_{2}^{2}
$$

å¯¹åç½®bä¸è¿›è¡Œæ­£åˆ™åŒ–ï¼Œåªå¯¹æƒé‡wè¿›è¡Œæ­£åˆ™åŒ–ï¼Œå‡è®¾$\sum_{i=1}^{n} x_{i}=0$,
$$
\beta_{0}=\frac{1}{n} \sum_{i=1}^{n} y_{i}
$$

$$
\min _{\beta, \beta_{0}} \sum_{i=1}^{n}\left(y_{i}-\boldsymbol{\beta}^{T} x_{i}-\beta_{0}\right)^{2}+\lambda \sum_{j=1}^{p}\left|\beta_{j}\right|^{q}
$$
### L2-æ­£åˆ™åŒ–

q=2ï¼Œï¼Œä½¿ç”¨L2èŒƒæ•°æ­£åˆ™åŒ–ç§°ä¸ºridge regressionï¼Œå²­å›å½’
$$
\min _{\boldsymbol{\beta}, \boldsymbol{\beta}_{0}} \sum_{i=1}^{n}\left(y_{i}-\boldsymbol{\beta}^{T} \boldsymbol{x}_{\boldsymbol{i}}-\beta_{0}\right)^{2}+\lambda \sum_{j=1}^{p}\left|\beta_{j}\right|^{q}åŒ–ä¸ºæœ‰çº¦æŸå½¢å¼ï¼šï¼ˆwhy ï¼Ÿ ä¸ºä»€ä¹ˆè¦è¿™æ ·åŒ–ï¼‰
$$

$$
\begin{array}{l}\min _{\boldsymbol{\beta}, \beta_{0}} \sum_{i=1}^{n}\left(y_{i}-\boldsymbol{\beta}^{T} \boldsymbol{x}_{i}-\beta_{0}\right)^{2} \\ \text { s. t. }\|\boldsymbol{\beta}\|^{2} \leq t\end{array}
$$
æ±‚è§£æ–¹æ³•ï¼šåŒ–ä¸ºçŸ©é˜µå½¢å¼ï¼Œåˆ©ç”¨æ­£è§„æ–¹ç¨‹æ³•å¯¹å…¶è¿›è¡Œæ±‚è§£
$$
L = \|Y-X \beta\|^{2} +\lambda||\beta||^2
$$
å¯¹æƒé‡å‚æ•°æ±‚åå¯¼ï¼ŒäºŒèŒƒæ•°çš„çŸ©é˜µè¡¨ç¤º
$$
\|x\|_{2}=\sqrt{\sum_{i=1}^{n} x_{i}^{2}}=\sqrt{\mathbf{X}^T \mathbf{X}}
$$

$$
\frac{\partial L}{\partial \beta}=2 X^T(X \beta-Y)+2 \lambda \beta=0
$$

$$
\Rightarrow X^T X \beta-X^T Y+\lambda \beta=0
$$

$$
\Rightarrow \left(X^TX+\lambda\right) \beta=X^T Y
$$
æ±‚è§£å¾—åˆ°ï¼š
$$
\Rightarrow \beta=\left(X^TX+\lambda I\right)^{-1} X^T Y
$$
#### ï¼ˆ*ï¼‰SVD å¥‡å¼‚å€¼åˆ†è§£

ç”¨SVDè§£é‡Šå²­å›å½’: $ğ‘‹=ğ‘ˆğ·ğ‘‰^ğ‘‡$ï¼Œğ‘ˆä¸ºğ‘›Ã—ğ‘,ğ‘‰ä¸ºğ‘Ã—ğ‘æ­£äº¤çŸ© é˜µï¼Œğ·ä¸ºå¯¹è§’é˜µï¼Œæ»¡è¶³ğ‘‘1 â‰¥ğ‘‘2 â‰¥â‹¯â‰¥ğ‘‘ğ‘ â‰¥0
$$
\begin{aligned} \mathbf{X} \hat{\beta}^{\mathrm{ls}} &=\mathbf{X}\left(\mathbf{X}^{T} \mathbf{X}\right)^{-1} \mathbf{X}^{T} \mathbf{y} \\ &=\mathbf{U} \mathbf{U}^{T} \mathbf{y} \\ \mathbf{X} \hat{\beta}^{\text {ridge }} &=\mathbf{X}\left(\mathbf{X}^{T} \mathbf{X}+\lambda \mathbf{I}\right)^{-1} \mathbf{X}^{T} \mathbf{y} \\ &=\mathbf{U} \mathbf{D}\left(\mathbf{D}^{2}+\lambda \mathbf{I}\right)^{-1} \mathbf{D} \mathbf{U}^{T} \mathbf{y} \\ &=\sum_{j=1}^{p} \mathbf{u}_{j} \frac{d_{j}^{2}}{d_{j}^{2}+\lambda} \mathbf{u}_{j}^{T} \mathbf{y} \end{aligned}
$$
### L1-æ­£åˆ™åŒ–

Least Absolute Shrinkage and Selection Operator, Lassoå›å½’

q=1ï¼Œwå˜æˆ0ï¼Œè‡ªåŠ¨æ”¾å¼ƒç‰¹å¾ï¼Œèµ·åˆ°ç‰¹å¾é€‰æ‹©ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆçš„æ–¹æ³•ï¼Œå¯ä»¥ä½¿å¾—ç‰¹å¾çŸ©é˜µç¨€ç–ã€‚
$$
\begin{array}{l}\min _{\boldsymbol{\beta}, \boldsymbol{\beta}_{0}} \sum_{i=1}^{n}\left(y_{i}-\boldsymbol{\beta}^{T} \boldsymbol{x}_{\boldsymbol{i}}-\beta_{0}\right)^{2} \\ \text { s.t. }\|\boldsymbol{\beta}\|_{1} \leq t\end{array}
$$
ç­‰ä»·æ‹‰æ ¼æœ—æ—¥è¡¨è¾¾å½¢å¼ï¼Œç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•ï¼ŒåŒ–æœ‰æ¡ä»¶æå€¼ä¸ºæ— æ¡ä»¶æå€¼ï¼š
$$
\min _{\boldsymbol{\beta}, \boldsymbol{\beta}_{0}} \sum_{i=1}^{n}\left(y_{i}-\boldsymbol{\beta}^{T} \boldsymbol{x}_{\boldsymbol{i}}-\beta_{0}\right)^{2}+\lambda\|\boldsymbol{\beta}\|_{1}
$$
L1çº¦æŸä½¿å¾—è§£å…³äº ğ’š éçº¿æ€§ï¼Œè€Œä¸”ä¸èƒ½åƒå²­å›å½’é‚£æ ·å¯ä»¥å¾— åˆ°å°é—­è§£ã€‚

1. é—­å¼è§£éœ€è¦æ»¡è¶³æ­£äº¤æ€§$X^TX=I$
2. ä¸€èˆ¬æ–¹æ³•Lassoå›å½’æ±‚è§£(ä¸€èˆ¬æƒ…å½¢): åæ ‡ä¸‹é™æ³•(CoordinateDescent)
    ç›¸å½“äºæ¯æ¬¡è¿­ä»£éƒ½åªæ˜¯æ›´æ–°xçš„ä¸€ä¸ª ç»´åº¦ï¼Œå³æŠŠè¯¥ç»´åº¦å½“åšå˜é‡ï¼Œå‰©ä¸‹ çš„n-1ä¸ªç»´åº¦å½“ä½œå¸¸é‡,é€šè¿‡æœ€å°åŒ–f(x) æ¥æ‰¾åˆ°è¯¥ç»´åº¦å¯¹åº”çš„æ–°çš„å€¼ã€‚
3. åæ ‡ ä¸‹é™æ³•å°±æ˜¯é€šè¿‡è¿­ä»£åœ°æ„é€ åºåˆ— $x^{0}, x^{1}, x^{2},...$æ¥æ±‚è§£é—®é¢˜ï¼Œå³ æœ€ç»ˆç‚¹æ”¶æ•›åˆ°æœŸæœ›çš„å±€éƒ¨æå°å€¼ç‚¹

  

### Lassoå›å½’
$$
\min _{\boldsymbol{\beta}, \beta_{0}} \sum_{i=1}^{n}\left(y_{i}-\boldsymbol{\beta}^{T} \boldsymbol{x}_{i}-\beta_{0}\right)^{2}+\lambda\|\boldsymbol{\beta}\|_{1}
$$
æ¯æ¬¡é’ˆå¯¹ä¸€ä¸ªå±æ€§è¿›è¡Œæ›´æ–°ï¼Œä¸ºä»€ä¹ˆ$\beta_0$ä¸‹é¢çš„æ¨åˆ°æ²¡äº†
$$
\mathrm{L}=\sum_{i=1}^{n}\left(y_{i}-\sum_{j=1}^{p} x_{i, j} \beta_{j}\right)^{2}+\lambda \sum_{j=1}^{p}\left|\beta_{j}\right|
$$
å®Œå…¨å¹³æ–¹å¼å±•å¼€ï¼ŒLå¯¹æƒé‡å‚æ•°æ±‚å¯¼
$$
\frac{\partial L}{\partial \beta_{k}}=2 a_{k}+2 b_{k} \beta_{k}+\lambda \operatorname{sign}\left(\beta_{k}\right), \\\text { where } a_{k}=\sum_{i=1}^{n} x_{i, k}\left(\sum_{j \neq k}^{p} x_{i, j} \beta_{j}-y_{i}\right), b_{k}=\sum_{i=1}^{n} x_{i, k}^{2}
$$
åˆ©ç”¨$\frac{\partial L}{\partial \beta_{k}}=0 $,å¾—åˆ°
$$
\beta_{k}=\left\{\begin{array}{l}-\frac{1}{b_{k}}\left(a_{k}-\frac{\lambda}{2}\right), \quad a_{k}>\frac{\lambda}{2} \\ 0, \quad-\frac{\lambda}{2}<a_{k}<\frac{\lambda}{2} \\ -\frac{1}{b_{k}}\left(a_{k}+\frac{\lambda}{2}\right), a_{k}<-\frac{\lambda}{2}\end{array}\right.
$$



## ç¨€ç–è¡¨ç¤ºå­—å…¸å­¦ä¹ 

å­—å…¸å­¦ä¹ ï¼šç»™å®šæ•°æ®é›†${x_1, x_2, ..., x_n}$
$$
\min _{B, \alpha_{i}} \sum_{i=1}^{n}\left(\left\|x_{i}-B \alpha_{i}\right\|^{2}+\lambda\left\|\alpha_{i}\right\|_{1}\right)
$$

- å…¶ä¸­ğ‘© âˆˆ ğ‘…ğ‘Ã—ğ‘˜ ä¸ºå­—å…¸çŸ©é˜µï¼Œ ğ‘˜ä¸ºå­—å…¸çš„è¯æ±‡é‡(é€šå¸¸ç”±ç”¨æˆ·æŒ‡å®š)ï¼Œ ğœ¶ğ’Š âˆˆ ğ‘…ğ‘˜æ˜¯æ ·æœ¬ğ’™ğ‘– âˆˆ ğ‘…ğ‘ çš„ç¨€ç–è¡¨ç¤ºã€‚

æ±‚è§£æ–¹æ³•ï¼šäº¤æ›¿ä¼˜åŒ–ï¼ˆæ§åˆ¶å˜é‡æ³•ï¼‰

1. å›ºå®šBï¼Œä¼˜åŒ–$\alpha$---Lassoå›å½’é—®é¢˜-------åæ ‡ä¸‹é™æ³•æ±‚è§£
2. å›ºå®š$\alpha$,ä¼˜åŒ–B-----çº¿å½¢ä¼˜åŒ–-------æ­£è§„æ–¹ç¨‹æ³•æ±‚è§£



# é›†æˆå­¦ä¹ 

æ€æƒ³ï¼šæ°‘ä¸»å†³ç­–ï¼Œå°‘æ•°æœä»å¤šæ•°

å¥½çš„é›†æˆï¼šä¸ªä½“è¦æœ‰å·®å¼‚ï¼Œä¸ªä½“ç²¾åº¦ä¸èƒ½å¤ªä½ï¼šå¥½è€Œä¸åŒ



é›†æˆçš„æœ‰æ•ˆæ€§ï¼š
$$
H(\boldsymbol{x})={\operatorname{sign}}\left(\sum_{i=1}^{T} h_{i}(\boldsymbol{x})\right)
$$

åˆ†ç±»é”™è¯¯ç‡éšç€Tçš„å¢å¤§å‘ˆæŒ‡æ•°ä¸‹é™
$$
\begin{aligned} P(\stackrel{H(\boldsymbol{x})} \neq {f(\boldsymbol{x})}) &=\sum_{k=0}^{\lfloor T / 2\rfloor}\left(\begin{array}{c}T \\ k\end{array}\right)(1-\epsilon)^{k} \epsilon^{T-k} \\ & \leqslant \exp \left(-\frac{1}{2} T(1-2 \epsilon)^{2}\right) \end{aligned}
$$

## é‡é‡‡æ ·

è‡ªé€‚åº”æƒé‡é‡ç½®å’Œç»„åˆ

1. éšæœºé‡‡æ ·ï¼šbagging
2. å¸¦æƒé‡‡æ ·ï¼šboosting



## ä¸²è¡Œå¼

ç‰¹ç‚¹ï¼šå¼ºä¾èµ– 

ä»£è¡¨æ€§ï¼šboosting---æƒå€¼é€æ¸å˜å¤§



### Boosting 

#### ç®—æ³•æ­¥éª¤

1. ç»™æ‰€æœ‰è®­ç»ƒæ ·ä¾‹èµ‹äºˆç›¸åŒçš„æƒé‡
2. è®­ç»ƒç¬¬ä¸€ä¸ªåŸºæœ¬åˆ†ç±»å™¨
3. å¯¹åˆ†ç±»é”™è¯¯çš„**æµ‹è¯•æ ·ä¾‹**æé«˜å…¶æƒé‡
4. ç”¨è°ƒæ•´è¿‡çš„å¸¦æƒ**è®­ç»ƒé›†**è®­ç»ƒç¬¬äºŒä¸ªåŸºæœ¬åˆ†ç±»å™¨
5. é‡å¤ä¸Šè¿°è¿‡ç¨‹

6. å¯¹æ‰€æœ‰çš„åŸºåˆ†ç±»å™¨è¿›è¡ŒåŠ æƒç»„åˆ

$$
H_{M}(x)=\operatorname{sign}\left(\sum_{m=1}^{M} \alpha_{m} h_{m}(x)\right)
$$

$h_m$æ˜¯åŸºåˆ†ç±»å™¨ï¼Œ$w_n^m$è¡¨ç¤ºæ ·æœ¬æƒé‡ï¼Œnä¸ºæ ·æœ¬æ•°é‡ï¼Œmä¸ºä¸ªä½“åˆ†ç±»å™¨æ•°

- å¯¹äºåˆ†ç±»é”™è¯¯çš„æ ·æœ¬--æé«˜å…¶æƒé‡



#### ğŸ‘Ada boosting

è€ƒè¯•ä¼šè€ƒ

##### æ¨¡å‹

äºŒåˆ†ç±»é—®é¢˜ï¼š

Nä¸ªè®­ç»ƒæ ·æœ¬ï¼š$x_{n}(n=1, \ldots, N)$

æ¯ä¸ªè®­ç»ƒæ ·æœ¬çš„æ ‡ç­¾ä¸º$y_{n} \in\{-1,+1\}, \quad h_{m}(x) \in\{-1,+1\}$



##### ç®—æ³•æ­¥éª¤ï¼š

1. åˆå§‹åŒ–æ¯ä¸ªè®­ç»ƒæ ·æœ¬çš„æƒé‡$w_n$: $w_{n}^{(1)}=1 / N$ï¼Œå‡åŒ€åˆ†é…
2. ç¬¬ä¸€ä¸ªåŸºåˆ†ç±»å™¨å¼€å§‹è®­ç»ƒï¼Œé€šè¿‡æœ€å°åŒ–è¯¯å·®å‡½æ•°$min L_{m}=\sum_{n=1}^{N} w_{n}^{(m)} I\left(h_{m}\left(x_{n}\right) \neq y_{n}\right)$ï¼Œ$I$ä¸ºæŒ‡ç¤ºå‡½æ•°ï¼Œè®­ç»ƒåˆ†ç±»å™¨$h_m$çš„å‚æ•°
3. è®¡ç®—åŠ æƒçš„åˆ†ç±»é”™è¯¯ç‡$\epsilon_{m}=\frac{\sum_{n=1}^{N} w_{n}^{(m)} I\left(h_{m}\left(x_{n}\right) \neq y_{n}\right)}{\sum_{n=1}^{N} w_{n}^{(m)}}$ï¼Œé”™è¯¯ç‡é€æ¸é™ä½
4. è®¡ç®—åˆ†ç±»å™¨æƒé‡$\alpha_{m}=\ln \frac{1-\epsilon_{m}}{\epsilon_{m}}$ï¼Œåˆ†ç±»æƒé‡é€æ¸å¢å¤§
5. æ›´æ–°æ ·æœ¬æƒé‡$w_{n}^{(m+1)}=w_{n}^{(m)} \exp \left(\alpha_{m} I\left(h_{m}\left(x_{n}\right) \neq y_{n}\right)\right)$
6. ä½¿ç”¨$H_M(x) = sign(\sum_{m=1}^M\alpha_m h_m(x))$



#### Error model



## å¹¶è¡Œå¼

ä¸å­˜åœ¨å¼ºä¾èµ–

### å†³ç­–æ ‘





# è´å¶æ–¯åˆ†ç±»å™¨

xæ ·æœ¬ï¼Œcä¸ºæ ‡ç­¾

åˆ¤åˆ«å¼æ¨¡å‹ï¼š

ç”Ÿæˆå¼æ¨¡å‹ï¼š

GANï¼šå¯¹æŠ—ç”Ÿæˆç½‘ç»œ

DCGANï¼š

## æ¨¡å‹

åŸºäºè´å¶æ–¯å…¬å¼çš„åéªŒæ¦‚ç‡ï¼š
$$
\begin{aligned} P\left(C=c_{i} \mid \mathbf{X} = \mathbf{x}\right) &=\frac{P\left(\mathbf{X}=\mathbf{x} \mid C=c_{i}\right) P\left(C=c_{i}\right)}{P(\mathbf{X}=\mathbf{x})} \\ & \propto P\left(\mathbf{X}=\mathbf{x} \mid C=c_{i}\right) P\left(C=c_{i}\right) \\ &  \text { for } i=1,2, \cdots, L \end{aligned}
$$
## è´å¶æ–¯åˆ†ç±»

$$
\underset{c_{i} \in C}{\operatorname{argmax}} {P\left(x_{1}, x_{2}, \ldots, x_{p} \mid c_{j}\right) P\left(c_{j}\right)}
$$
### æœ´ç´ è´å¶æ–¯åˆ†ç±»

æœ´ç´ æ¡ä»¶ï¼šå¯¹å·²çŸ¥ç±»åˆ«ï¼Œå‡è®¾æ‰€æœ‰å±æ€§äº’ç›¸å¯¹ç«‹
$$
\begin{aligned} P\left(X_{1}, X_{2}, \cdots, X_{p} \mid C\right) &=P\left(X_{1} \mid X_{2}, \cdots, X_{p}, C\right) P\left(X_{2}, \cdots, X_{p} \mid C\right) \\ &=P\left(X_{1} \mid C\right) P\left(X_{2}, \cdots, X_{p} \mid C\right) \\ &=P\left(X_{1} \mid C\right) P\left(X_{2} \mid C\right) \cdots P\left(X_{p} \mid C\right) \end{aligned}
$$
æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨æ¨¡å‹ï¼ˆè”åˆè½¬åŒ–ä¸ºè¿ä¹˜ï¼‰ï¼š
$$
\arg \max _{c_{j} \in C} P\left(c_{j}\right) \prod_{i=1}^{P} P\left(x_{i} \mid c_{j}\right)
$$
éœ€è¦ä¼°è®¡ï¼š

- å…ˆéªŒ$ğ‘ƒ (ğ¶ = ğ‘_ğ‘— )$
- æ¯ä¸ªå±æ€§çš„æ¡ä»¶æ¦‚ç‡$ğ‘ƒ(ğ‘¥_ğ‘–|ğ‘_ğ‘—)$

#### é¿å…0æ¦‚ç‡é—®é¢˜

è‹¥æŸä¸ªå±æ€§å€¼åœ¨è®­ç»ƒé›†ä¸­æ²¡æœ‰ä¸æŸä¸ªç±»åŒæ—¶å‡ºç°è¿‡ï¼Œåˆ™åŸºäºé¢‘ç‡çš„æ¦‚ç‡ä¼°è®¡å°†ä¸ºé›¶ã€‚

ä¿®æ­£ï¼šåœ¨åˆ†æ¯ä¸Š+å±æ€§å–å€¼æ•°ç›®ï¼Œåˆ†å­åŠ ä¸Šç±»çš„ä¸ªæ•°
$$
\hat{P}\left(X_{\mathrm{i}}=x \mid C=c_{j}\right)=\frac{N\left(X_{\mathrm{i}}=x \mid C=c_{j}\right)+1}{N\left(C=c_{j}\right)+\left|X_{i}\right|}
$$
### é«˜æ–¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨

#### é«˜æ–¯åˆ†å¸ƒ

$$
\mathcal{N}(\mathbf{x} \mid \boldsymbol{\mu}, \boldsymbol{\Sigma})=\frac{1}{(2 \pi) \mathbf{P} / 2} \frac{1}{|\boldsymbol{\Sigma}|^{1 / 2}} \exp \left\{-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^{\mathrm{T}} \boldsymbol{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})\right\}
$$
ä¸€ç»´Gaussianï¼š

å‡å€¼å’Œæ–¹å·®çš„æå¤§ä¼¼ç„¶ä¼°è®¡å€¼åˆ†åˆ«æ˜¯æ ·æœ¬çš„å‡å€¼åŠæ ·æœ¬çš„æ–¹å·®
$$
\mu=\frac{1}{n} \sum_{i=1}^{n} x_{i}, \quad \sigma^{2}=\frac{1}{n} \sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}
$$
å¤šç»´ Gaussianï¼š
$$
\mu=\frac{1}{n} \sum_{i=1}^{n} x_{i}, \quad \Sigma=\frac{1}{n} \sum_{i=1}^{n}\left(x_{i}-\mu\right)\left(x_{i}-\mu\right)^{T}
$$
### é«˜æ–¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨

$$
\underset{C}{\operatorname{argmax}} P(C \mid X)=\underset{C}{\operatorname{argmax}} P(X, C)=\underset{C}{\operatorname{argmax}} P(X \mid C) P(C)
$$

$$
\hat{P}\left(x_{i} \mid C=c_{j}\right)=\frac{1}{\sqrt{2 \pi} \sigma_{i j}} \exp \left(-\frac{\left(x_{i}-\mu_{i j}\right)^{2}}{2 \sigma_{i j}^{2}}\right)
$$

xæ ·æœ¬ï¼Œcä¸ºæ ‡ç­¾

ç”±Xå¾—åˆ°é«˜æ–¯åˆ†å¸ƒçš„å‡å€¼å’Œæ–¹å·®ï¼Œåä»£å…¥é«˜æ–¯åˆ†å¸ƒ

$P(å¯†åº¦\midå¥½ç“œ) = P(å¯†åº¦\midå¥½ç“œ)*P(å«ç³–ç‡\midå¥½ç“œ)$



æœ´ç´ ï¼šç”¨æ‰€æœ‰æ ·æœ¬

éæœ´ç´ ï¼šè”åˆç­‰äºä¸¤ä¸ªä¹˜ç§¯

$å…±æœ‰ LÃ—(p+pÃ— (p+1)/2)ä¸ªå‚æ•°$

$\sum:pÃ—p$

$\mu:p$

æœ´ç´ é«˜æ–¯å¿…è¦æ€§ï¼šä¼°è®¡çš„å‚æ•°é‡å‡å°‘



é€»è¾‘å›å½’å†³ç­–é¢ï¼š$\theta^TX = 0$

é«˜æ–¯è´å¶æ–¯å†³ç­–é¢ï¼š

åˆ†åˆ°lç±»å’Œkç±»çš„æ¦‚ç‡ç›¸ç­‰
$$
\log P\left(c_{k} \mid x\right)-\log P\left(c_{l} \mid x\right)=0
$$

ç”¨è´å¶æ–¯å…¬å¼å±•å¼€
$$
\log \frac{P\left(C_{k} \mid X\right)}{P\left(C_{1} \mid X\right)}=\log \frac{P\left(X \mid C_{k}\right)}{P\left(X \mid C_{l}\right)}+\log \frac{P\left(C_{k}\right)}{P\left(C_{l}\right)}
$$
å…¶ä¸­
$$
\log P\left(x \mid c_{k}\right)=-\frac{1}{2}\left(\mathrm{x}-{\mu}_{k}\right)^{T} {\sum_{k}}^{-1}\left(x-\mu_{k}\right)-\log \left|\Sigma_{k}\right|^{\frac{1}{2}}
$$

$$
\begin{array}{l}\log \frac{P\left(c_{k} \mid \mathrm{x}\right)}{P\left(c_{l} \mid x\right)} \\ =\frac{1}{2}\left(\mathrm{x}-\mu_{l}\right)^{T} \Sigma_{l}{ }^{-1}\left(x-\mu_{l}\right)-\frac{1}{2}\left(\mathrm{x}-\mu_{k}\right)^{T} \Sigma_{k}{ }^{-1}\left(x-\mu_{k}\right)+\log \frac{\left|\Sigma_{l}\right|^{\frac{1}{2}}}{\left|\Sigma_{k}\right|^{\frac{1}{2}}}+\log \frac{\pi_{k}}{\pi_{l}}\end{array}
$$

å‡è®¾æ¯ä¸€ç±»çš„åæ–¹å·®çŸ©é˜µå‡ç›¸åŒï¼Œ

$$
\sum_{\boldsymbol{k}}=\sum, \forall \boldsymbol{k}
$$

$$
\Sigma_{j}=\left[\begin{array}{ccc}\sigma_{1 j}^{2} & \cdots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \cdots & \sigma_{p j}^{2}\end{array}\right]
$$

å†³ç­–å‡½æ•°å¯ä»¥ä»xçš„äºŒæ¬¡è½¬ä¸ºä¸€æ¬¡å‡½æ•°
$$
\begin{aligned}=& \log \frac{\pi_{k}}{\pi_{l}}+\frac{1}{2}\left(\mathrm{x}-\mu_{l}\right)^{T} \Sigma^{-1}\left(x-\mu_{l}\right)-\frac{1}{2}\left(\mathrm{x}-\mu_{k}\right)^{T} \Sigma^{-1}\left(x-\mu_{k}\right) \\=& \frac{\log \frac{\pi_{k}}{\pi_{l}}+\frac{1}{2} \mu_{l}^{T} \Sigma^{-1} \mu_{l}-\frac{1}{2} \mu_{k}^{T} \Sigma^{-1} \mu_{k}}{\mathrm{~b}}+x^{T} \frac{\Sigma^{-1}\left(\mu_{k}-\mu_{l}\right)}{\mathrm{a}} \end{aligned}
$$
å†³ç­–è¾¹ç•Œï¼š
$$
x^{T} \mathrm{a}+b=0
$$
è¦ä¼°è®¡çš„å‚æ•°ä¸ªæ•°ï¼š$LÃ—(p+pÃ— (p+1)/2)$

è‹¥ $a_{0}+\sum_{i=1}^{p} a_{j} x_{j}>0$ï¼Œå°†ğ‘¥çš„æ ‡ç­¾ç½®ä¸ºğ‘1ï¼Œå¦åˆ™å°†å…¶æ ‡ç­¾ ç½®ä¸ºğ‘2



## LDAå†³ç­–é¢

é€šè¿‡å‡è®¾æ¯ä¸€ç±»å…·æœ‰çš„ç›¸åŒåæ–¹å·®çŸ©é˜µï¼Œå¾—åˆ°ä¸€ç§ç»å…¸ çš„çº¿æ€§å­¦ä¹ æ–¹æ³•ï¼šçº¿æ€§åˆ¤åˆ«åˆ†æï¼ˆLinear Discriminant Analysis, LDAï¼‰

çº¿å½¢å†³ç­–é¢
$$
\begin{array}{l}=\log \frac{\pi_{k}}{\pi_{l}}+\frac{1}{2}\left(\mathrm{x}-\mu_{l}\right)^{T} \Sigma^{-1}\left(x-\mu_{l}\right)-\frac{1}{2}\left(\mathrm{x}-\mu_{k}\right)^{T} \Sigma^{-1}\left(x-\mu_{k}\right) \\ =\log \frac{\pi_{k}}{\pi_{l}}+\frac{1}{2} \mu_{l}^{T} \Sigma^{-1} \mu_{l}-\frac{1}{2} \mu_{k}^{T} \Sigma^{-1} \mu_{k}+x^{T} {\Sigma^{-1}\left(\mu_{k}-\mu_{l}\right)}\end{array}
$$

### å‚æ•°ä¼°è®¡

å…ˆéªŒï¼š
$$
\widehat{P}\left(C=C_{j}\right)=\frac{N\left(C=c_{j}\right)}{N}
$$
å‡å€¼ï¼šç¬¬jä¸ªé«˜æ–¯åˆ†å¸ƒçš„å‡å€¼
$$
\mu_{j}=\frac{1}{N\left(C=c_{j}\right)} \sum_{X \in c_{j}} X
$$
æ–¹å·®ï¼š
$$
\Sigma=\frac{1}{N} \sum_{c_{j} \in C} \sum_{X \in c_{j}}\left(X-\mu_{j}\right)\left(X-\mu_{j}\right)^{T}
$$
ğŸ‘æ±‚å†³ç­–è¾¹ç•Œ

å·²çŸ¥ç›¸åº”çš„å‚æ•°ï¼š
$$
\begin{array}{l}\begin{array}{l}* \pi_{1}=\pi_{2}=0.5 \\ * \mu_{1}=(0,0)^{T}, \mu_{2}=(2,-2)^{T}\end{array} \\ * \Sigma=\left(\begin{array}{cc}1.0 & 0.0 \\ 0.0 & 0.5625\end{array}\right)\end{array}
$$
åˆ™ä»£å…¥ä¸Šè¿°å…¬å¼æ±‚å¾—å†³ç­–è¾¹ç•Œï¼š
$$
\text { *Decision boundary: } 5.56-2.00 x_{1}+3.56 x_{2}=0.0
$$

Loss function

| é€»è¾‘å›å½’         | LDA               |
| ---------------- | ----------------- |
| æ— ğ‘¥ çš„åˆ†å¸ƒå‡è®¾ï¼š | å‡è®¾ğ‘¥æœä»é«˜æ–¯åˆ†å¸ƒ |

é€»è¾‘å›å½’--åˆ¤åˆ«å¼
$$
\begin{array}{l}{L = P(c \mid x ; \theta)}=\left(f_{\theta}(x)\right)^{c}\left(1-\frac{f_{\theta}}{\theta}(x)\right)^{1-c} \\ \theta^{(0)} \quad \theta^{(1)}:=\theta^{(0)}+\left.\alpha^{+\frac{e^{-\theta^{T}-x}}{\partial \theta}}\right|_{\theta^{(0)}}\end{array}
$$
LDA--ç”Ÿæˆå¼
$$
\begin{array}{l}P\left(x \mid c_{k}\right) \sim M\left(\mu_{k}, \Sigma_{h}\right) \\ =\frac{1}{(2 \pi)^{\frac{p}{2}} \mid \Sigma_{k} \cdot \frac{1}{2}} \exp -\frac{1}{2}\left(\mathrm{x}-\mu_{k}\right)^{T} \sum_{k}^{-1}\left(x-\mu_{k}\right) \\ \text { å…¶ä¸­ } \Sigma_{k}=\Sigma, \forall k . \quad \mu_{k}=\frac{1}{1} \sum_{\frac{2}{2}} x_{i} \\ \text { å†³ç­–è¾¹ç•Œ çº¿æ€§ } \sum_{k}=\frac{1}{h} \overline{2}\end{array}
$$

é«˜æ–¯æœ´ç´ è´å¶æ–¯å†³ç­–é¢




# K-NNåˆ†ç±»ç®—æ³•

K-è¿‘é‚» ï¼ˆK-nearest neighborsï¼‰

å¯¹ä¸€ä¸ªæœªçŸ¥æ ·æœ¬è¿›è¡Œåˆ†ç±»ï¼š

1. è®¡ç®—æœªçŸ¥æ ·æœ¬ä¸æ ‡è®°æ · æœ¬çš„è·ç¦»

2. ç¡®å®š k ä¸ªè¿‘é‚» 

3. ä½¿ç”¨è¿‘é‚»æ ·æœ¬çš„æ ‡ç­¾ç¡®å®šç›®æ ‡çš„æ ‡ç­¾ï¼š

   ä¾‹å¦‚ï¼Œ å°†å…¶åˆ’åˆ†åˆ° kä¸ªæ ·æœ¬ä¸­ å‡ºç°æœ€é¢‘ç¹çš„ç±»

æ²¡æœ‰æ¨¡å‹ï¼Œæ²¡æœ‰error model

KNNå›å½’



# é©¬å°”å¯å¤«é“¾

Markovæ¨¡å‹ï¼ˆé“¾ï¼‰

## è´å¶æ–¯ç½‘

æœ‰å‘æ— ç¯å›¾

ç‰¹å¾å˜é‡ä¹‹é—´çš„













![image-20211108090515589](/Users/wangjing/Library/Application Support/typora-user-images/image-20211108090515589.png)

1æ­¥è½¬ç§»
$$
\begin{array}{l}v_{t+1}(j)=P\left(X_{t+1}=j\right) \\ =\sum_{i=1}^{K} P\left(X_{t}=i\right) P\left(X_{t+1}=j \mid X_{t}=i\right)=\sum_{i=1}^{K} v_{t}(i) \mathrm{A}_{i j}=v_{t} \mathrm{~A}(:, \mathrm{j})\end{array}
$$
næ­¥è½¬ç§»
$$
P({\mathrm{X}_{1}}=i_{1}, \ldots, \mathrm{X}_{T}=i_{T})=\pi_{i_{1}} \prod_{t=2}^{T} A_{i_{t-1} i_{t}}
$$

## å¹³ç¨³åˆ†å¸ƒ

å¹³ç¨³åˆ†å¸ƒï¼šå¯¹äºä¸€ä¸ªMarkové“¾ï¼Œç»™å®šåˆå§‹çŠ¶æ€åˆ†å¸ƒ ğ‘£1 = ğœ‹ = ğ‘ƒ ğ‘‹1 = 1 , ... , ğ‘ƒ ğ‘‹1 = ğ¾ ï¼Œåˆ©ç”¨çŠ¶æ€è½¬ç§» å…¬å¼ğ‘£ğ‘¡+1=ğ‘£ğ‘¡Aï¼Œç»è¿‡ä¸€å®šæ¬¡æ•°çš„è¿­ä»£ä¹‹åï¼Œè‹¥èƒ½è¾¾åˆ° à·¤ ğ‘£= à·¤ ğ‘£A åˆ™ç§°Markové“¾è¾¾åˆ°äº†å¹³ç¨³åˆ†å¸ƒã€‚ ï°ä¸€æ—¦è¿›å…¥å¹³ç¨³åˆ†å¸ƒï¼Œåœ¨ä¹‹åçš„ä»»æ„æ—¶åˆ»çš„æ¦‚ç‡åˆ†å¸ƒ æ°¸è¿œä¸º à·¤ ğ‘£ï¼Œé©¬å°”å¯å¤«é“¾å¤„äºç¨³å®šçŠ¶æ€ ç¨³å®šçŠ¶æ€ï¼š à·¤ ğ‘£ç»è¿‡Aè½¬ç§»åä»ç„¶æ˜¯ à·¤ ğ‘£

åº”ç”¨

1. å¥å­è¡¥å…¨
2. ç½‘é¡µæ’åºï¼špage-rank

damping look è§£å†³æ–­é“¾é—®é¢˜

ğŸ‘å¹³ç¨³åˆ†å¸ƒçš„è®¡ç®—

## page-rank

PageRankè®¤ä¸ºæŸä¸ªç½‘é¡µçš„é‡è¦æ€§æœ‰ä¸¤ä¸ªå› ç´ å†³å®šï¼šæŒ‡ å‘ç½‘é¡µçš„é“¾æ¥æ•°é‡ä»¥åŠè¾“å‡ºç½‘é¡µçš„é“¾æ¥æ•°é‡ã€‚ 

è¶…é“¾æ¥çš„ä¸ªæ•°å’Œè´¨é‡

æ•°é‡å‡è®¾å’Œè´¨é‡å‡è®¾

è‹¥ç½‘é¡µğ‘—åˆ°ç½‘é¡µğ‘–æœ‰è¾¹ï¼Œåˆ™ä»¤ $ğ¿_{ğ‘–ğ‘—} = 1$ï¼Œå¦åˆ™ $ğ¿_{ğ‘–ğ‘—} = 0$ã€‚å›  æ­¤ï¼Œ $ğ‘—$çš„è¾“å‡ºé“¾æ¥ä¸ºï¼Œå‡ºé“¾çš„ä¸ªæ•°ï¼ˆæœ‰å‘å›¾å‡ºåº¦ï¼‰
$$
c_{j}=\sum_{i=1}^{N} L_{i j}
$$
æŒ‡å‘ç½‘é¡µçš„é“¾æ¥è¶Šå¤šæƒé‡è¶Šå¤§ï¼Œè€Œè¾“å‡ºç½‘é¡µçš„é“¾æ¥è¶Šå¤šæƒ é‡è¶Šå°
$$
p_{i}=(1-d)+d \sum_{j=1}^{N}\left(\frac{L_{i j}}{c_{j}}\right) p_{j}
$$
$p_i$ä¸ºä¸ºç½‘é¡µé‡è¦æ€§ï¼Œ$c_j$è¡¨ç¤ºç½‘é¡µjå¯¹ç½‘é¡µiçš„é‡è¦æ€§çš„ç¨‹åº¦



ğŸ‘å‚æ•°ä¼°è®¡è®¡ç®—

MLEæœ€å¤§ä¼¼ç„¶ä¼°è®¡for Markov chain



## HMMéšé©¬å°”å¯å¤«é“¾

HMMä¸‰ä¸ªé—®é¢˜

1. è¯„ä¼°é—®é¢˜ï¼šæ¦‚ç‡è®¡ç®—é—®é¢˜

   ä¼°è®¡æ¨¡å‹ä¸‹è§‚æµ‹åºåˆ—å‡ºç°çš„æ¦‚ç‡

2. è§£ç é—®é¢˜ï¼šçŠ¶æ€é¢„æµ‹é—®é¢˜

   ç»™å®šæ¨¡å‹å‚æ•°å’Œä¸€ä¸ªè§‚æµ‹åºåˆ—ï¼Œæ¨æ–­éšçŠ¶æ€ åºåˆ—

3. å­¦ä¹ é—®é¢˜ï¼šå‚æ•°ä¼°è®¡é—®é¢˜

   ç»™å®šå¤šä¸ªè§‚æµ‹æ•°æ®Yï¼Œä¼°è®¡ä¸€ç»„å‚æ•°

![image-20211108110010355](/Users/wangjing/Library/Application Support/typora-user-images/image-20211108110010355.png)

å¸¸è§„æ–¹æ³•ï¼šéå†--å¤æ‚åº¦æŒ‡æ•°çº§



# éç›‘ç£å­¦ä¹ 
--å‹ç¼©æ€æƒ³
1. çºµå‘ç»“æ„--èšç±»
2. æ¨ªå‘ç»“æ„--é™ç»´åº¦


çº¿å½¢ï¼š
éçº¿å½¢ï¼š

## èšç±»
clustering---ç°‡å†…è·å°ï¼Œç°‡é—´è·å¤§
ç°‡çš„å®šä¹‰
æ•°æ®è¡¨ç¤ºï¼šå‘é‡ç©ºé—´
ç›¸ä¼¼æ€§/è·ç¦»ï¼šæ¬§æ°è·ç¦»
ç°‡çš„ä¸ªæ•°ï¼šæ•°æ®é©±åŠ¨ï¼Œè‡ªå·±è¯†åˆ«å‡ºæ¥
èšç±»ç®—æ³•ï¼šåˆ’åˆ†èšç±»ç®—æ³•ï¼Œå±‚æ¬¡èšç±»ç®—æ³•
ç®—æ³•çš„æ”¶æ•›æ€§ï¼šæ”¶æ•›é€Ÿåº¦

å±‚æ¬¡å¼èšç±»ç®—æ³•
1. è‡ªé¡¶å‘ä¸Šï¼šèšåˆ
2. è‡ªé¡¶å‘ä¸‹ï¼šåˆ†è£‚

â­ï¸åˆ’åˆ†å¼èšç±»ç®—æ³•
1. K-means
2. GMMï¼ˆé«˜æ–¯æ··åˆæ¨¡å‹ï¼‰



## K-means

### æ¨¡å‹

ç®—æ³•æ­¥éª¤ï¼š

è¾“å…¥ï¼šæ•°æ®Nä¸ªæ ·æœ¬ï¼Œç°‡çš„ä¸ªæ•°æŒ‡å®šä¸ºK

1. åˆå§‹åŒ–ï¼šéšæœºé€‰æ‹©Kä¸ªæ•°æ®ç‚¹ä½œä¸ºç›¸åº”çš„ç°‡ä¸­å¿ƒ{}
2. è¿­ä»£ï¼š
   1. å¯¹æ¯ä¸€ä¸ªæ ·æœ¬è¥¿äº¤è¿›è¡Œå½’ç°‡ï¼Œè·ç¦»å“ªä¸ªèšç±»ä¸­å¿ƒæœ€è¿‘ï¼Œåˆ™è®²å…¶å½’ä¸ºå“ªä¸€ç°‡
   $x_{j} \in C_{i} \Leftrightarrow \min _{t=1, \ldots, K}\left\{\left\|x_{j}-\mu_{t}\right\|\right\}=\left\|x_{j}-\mu_{i}\right\|$
   2. é‡æ–°è®¡ç®—æ¯ä¸ªç°‡çš„å‡å€¼ï¼ˆç°‡ä¸­å¿ƒï¼‰$\mu_{i}=\frac{1}{\left|C_{i}\right|} \sum_{x_{j} \in C_{i}} x_{j}$
3. ç»ˆæ­¢è¿­ä»£ï¼šç°‡ä¸­å¿ƒä¸å‘ç”Ÿæ”¹å˜æ—¶

è¾“å‡ºï¼šç°‡ä¸­å¿ƒ

ç›®æ ‡å‡½æ•°ï¼šç°‡å†…æ ·æœ¬åˆ°ç°‡ä¸­å¿ƒçš„å¹³æ–¹å’Œè·ç¦»æœ€å°
$$
\operatorname{argmin}_{C, \mu} \sum_{i=1}^{K} \sum_{x_{j} \in C_{i}}\left\|x_{j}-\mu_{i}\right\|_{2}^{2}
$$
éå‡¸å‡½æ•°ï¼ŒNP-hard

è§£å†³ä¹‹é“ï¼šè¿­ä»£ä¼˜åŒ–ï¼ˆäº¤æ›¿ä¼˜åŒ–ï¼šå›ºå®šä¸€ç»„å˜é‡å€¼å»ä¼˜åŒ–å¦ä¸€ç»„å˜é‡å€¼ï¼‰

â€¢ åˆå§‹åŒ–Kä¸ªç°‡ä¸­å¿ƒ:ğœ‡ = {ğœ‡1, ğœ‡2, ... , ğœ‡ğ¾} â€¢ è¿­ä»£è¿›è¡Œä»¥ä¸‹ä¼˜åŒ–

â€¢ æ›´æ–°ç°‡æˆå‘˜:å›ºå®šğœ‡ï¼Œä¼˜åŒ–ğ¶ â€¢ æ›´æ–°ç°‡ä¸­å¿ƒ:å›ºå®šğ¶ï¼Œä¼˜åŒ–ğœ‡



#### ç®—æ³•å¤æ‚åº¦ï¼š

è¿­ä»£æ¬¡æ•°:å‡è®¾è¿­ä»£ ğ‘™ æ­¥ç®—æ³•æ”¶æ•›ã€‚å› æ­¤æ€»çš„è®¡ç®—å¤æ‚åº¦

ä¸º O(ğ‘™ ğ¾np)
 ç”±äºğ¾å’Œğ‘™é€šå¸¸éƒ½è¿œè¿œå°äºnï¼Œå¯è®¤ä¸ºæ˜¯å…³äºn çš„çº¿æ€§å¤æ‚åº¦

#### åˆå€¼å¯¹ç®—æ³•çš„å½±å“ï¼š

é€šè¿‡å¯å‘å¼æ–¹æ³•é€‰æ‹©å¥½çš„åˆå€¼:ä¾‹å¦‚è¦æ±‚ç§å­ç‚¹ä¹‹é—´æœ‰è¾ƒå¤§çš„è·ç¦» ïƒ˜å°è¯•å¤šä¸ªåˆå€¼ï¼Œé€‰æ‹©å¹³æ–¹è¯¯å·®å’Œæœ€å°çš„ä¸€ç»„èšç±»ç»“æœ

#### èšç±»æ•°ç›®Kçš„å½±å“ï¼š

æ‰‹è‚˜æ³•:ç›®æ ‡å‡½æ•°çš„å€¼å’Œ k çš„å…³ç³»å›¾æ˜¯ä¸€ä¸ªæ‰‹è‚˜çš„å½¢çŠ¶ï¼Œè€Œè¿™ä¸ªè‚˜éƒ¨ å¯¹åº”çš„kå€¼å°±æ˜¯æ•°æ®çš„æœ€ä½³èšç±»æ•°ã€‚k=2æ—¶ï¼Œå¯¹åº”è‚˜éƒ¨ï¼Œæ•…é€‰æ‹© kå€¼ä¸º2

#### å±€é™æ€§

ä¸é€‚åˆå¯¹å½¢çŠ¶ä¸æ˜¯è¶…ç»´æ¤­åœ†ä½“(æˆ–è¶…ç»´çƒä½“)çš„æ•°æ®



## K-meanså»¶ä¼¸

å±‚æ¬¡-kmeans

ä¹˜ç§¯é‡åŒ–ï¼šå°±æ˜¯åˆ’åˆ†æ•°æ®é›†ï¼Œç„¶ååˆ†åˆ«åˆ’åˆ†å‡ºèšç±»ä¸­å¿ƒï¼Œç„¶åå‘é‡ä¹˜ç§¯

128*n

nä¸ªæ ·æœ¬è®­ç»ƒ256ä¸ªclusterï¼šèšç±»ä¸­å¿ƒ

åˆ’åˆ†æ ·æœ¬é›†åšå®Œç¬›å¡å°”ä¹˜ç§¯ä¹‹åçš„ç»´æ•°å’Œç”¨åŸå§‹æ ·æœ¬æ±‚ä¸­å¿ƒçš„ç»´æ•°ä¸€æ ·å—ï¼Ÿ



# PCA

## æ ‡å‡†PCA

çº¿å½¢PCA

### ä¸‰ç§å»ºæ¨¡æ€æƒ³

PCA æ±‚è§£è§’åº¦

1. æœ€å¤§æŠ•å½±æ–¹å·®
2. æœ€å°æŠ•å½±è·ç¦»
3. å¥‡å¼‚å€¼åˆ†è§£(SVD)

#### æœ€å¤§æŠ•å½±æ–¹å·®

ä¿¡æ¯ï¼ˆæ–¹å·®ï¼‰èƒ½å°½å¯èƒ½å¤§çš„ä¿æŒ

#### æœ€å°æŠ•å½±è·ç¦»

æŠ•å½±æ•°æ®ä¸åŸæ•°æ®çš„ä¹‹é—´çš„æœ€å°å¹³æ–¹è·ç¦»å°½å¯èƒ½å°

ç›®æ ‡å‡½æ•°ï¼š
$$
\mathbf{w}_{1}=\arg \max _{|\mathbf{w}|-1} \frac{1}{m} \sum_{i=1}^{m}\left\{\left(\mathbf{w}^{T} \mathbf{x}_{i}\right)^{2}\right\} \quad \operatorname{Var}(X)=E\left\{[X-E(X)]^{2}\right\}
$$

$$
L=-w^{\top} A w+\lambda\left(w^{\top} w-1\right)\\
\frac{\partial L}{\partial w}=-2 \cdot A w+2 \lambda w=0 \Rightarrow A w=\lambda w \Rightarrow w^{\top} A w=\lambda
$$

 w1åæ–¹å·®çŸ©é˜µçš„æœ€å¤§ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡
$$
\max _{W \in R^{p * k}} \operatorname{tr}\left(W^{T}\left(\frac{1}{m} X X^{T}\right) W\right), W^{T} W=I_{k}
$$
 PCAä¸»æ–¹å‘ = æ•°æ®åæ–¹å·®çŸ©é˜µçš„ç‰¹å¾å‘é‡ â€¢ æ›´å¤§ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡æ›´åŠ é‡è¦
é™ç»´ç»“æœ

$$
Z=W^{T} X
$$
é‡æ„ç»“æœ
$$
\widehat{\mathrm{X}}=W Z=W W^{T} X
$$


ç›®æ ‡:è®¡ç®—æ•°æ®kä¸ªä¸»æ–¹å‘

- ç¬¬ä¸€æ­¥:æ•°æ®å±…ä¸­
- ç¬¬äºŒæ­¥:è®¡ç®—å±…ä¸­æ•°æ®çš„åæ–¹å·®çŸ©é˜µ
- ç¬¬ä¸‰æ­¥:è®¡ç®—åæ–¹å·®çŸ©é˜µæœ€å¤§kä¸ªç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾ å‘é‡ï¼Œç»„æˆçŸ©é˜µ

- è¾“å‡ºé™ç»´ç»“æœ

- é—®é¢˜:

  â€¢ ç¬¬kä¸ªä¸»æˆåˆ†çš„æ–¹å·®æ˜¯å¤šå°‘? 

  â€¢ k é€‰æ‹©å¤šå¤§
$$
  \begin{array}{l}w_{k}^{T}\left(\frac{1}{M} \sum_{i=1}^{M} x_{i} x_{i}^{T}\right) w_{k} \\ =w_{k}^{T} \lambda_{k} w_{k}=\lambda_{k} w_{k}^{T} w_{k}=\lambda_{k}\end{array}
$$
Kçš„é€‰æ‹©



### å¥‡å¼‚å€¼åˆ†è§£SVD
$$
A=U \Sigma V^{T}
$$


#### PCAåº”ç”¨-æ•°æ®é¢„å¤„ç†

æ•°æ®ç™½åŒ–(Whitening)æ“ä½œ

ä½¿ç”¨PCAï¼Œå¯ä»¥åŒæ—¶å»é™¤å˜é‡ä¹‹é—´çš„çº¿æ€§å…³ç³»ä»¥åŠå¯¹æ•°æ®è¿›è¡Œå½’ä¸€åŒ–:

- å‡è®¾æ•°æ®çš„åæ–¹å·®çŸ©é˜µä¸ºS
$$
  S=\frac{1}{m} \sum_{i=1}^m(x_{i}-\bar{x})(x_{i}-\bar{x})^{T}
$$

-  åˆ©ç”¨$W^{T} S W=\Lambda$å®šä¹‰ä¸€ä¸ªå˜æ¢
$$
y_{i}=\Lambda^{-\frac{1}{2}} W^{T}\left(x_{i}-\bar{x}\right)
$$

 åˆ™yçš„å‡å€¼ä¸º0ï¼Œåæ–¹å·®ä¸ºå•ä½çŸ©é˜µã€‚

## æ¦‚ç‡PCA

## æ ¸PCA

### æ­¥éª¤

1. è¾“å…¥
2. æ„é€ GramçŸ©é˜µ
3. å¯¹é«˜ç»´æ•°æ®å»ä¸­å¿ƒåŒ–
4. å¯¹Kè¿›è¡Œç‰¹å¾åˆ†è§£
5. è®¡ç®—xçš„ä½ç»´è¡¨ç¤º

## LLE

Locally Linear embedding å±€éƒ¨çº¿æ€§åµŒå…¥

LLEå…³æ³¨äºé™ç»´æ—¶ä¿æŒæ ·æœ¬å±€éƒ¨çš„çº¿æ€§ç‰¹å¾ï¼Œç”±äºLLEåœ¨é™ç»´æ—¶ä¿æŒäº†æ ·æœ¬çš„å±€éƒ¨ç‰¹å¾

1. æ‰¾æœ€è¿‘é‚»ï¼šæ¬§æ°è·ç¦»
2. é‡æ„ï¼šé‡æ„ç³»æ•°ä¹‹å’Œ=1

$$
\begin{aligned} \varepsilon(W) &=\sum_{i=1}^{N}\left\|x_{i}-\sum_{j=1}^{k} W_{i j} x_{i j}\right\|^{2} =\sum_{i=1}^{N}\left\|\sum_{j=1}^{k} W_{i j}\left(x_{i}-x_{i j}\right)\right\|^{2} \end{aligned}
$$
$W_{ij}$æ±‚è§£æ–¹æ³•ï¼šæ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•
$$
L\left(W_{i}\right)=W_{i}^{T} Z_{i} W_{i}+\lambda\left(W_{i}^{T} 1_{k \times 1}-1\right)
$$

$$
2 Z_{i} W_{i}+\lambda 1_{k \times 1}=0, \text { å³ } W_{i}=-\frac{\lambda}{2} Z_{i}^{-1} 1_{k \times 1}
$$



3. ä½ç»´åµŒå…¥ğŸ‘



